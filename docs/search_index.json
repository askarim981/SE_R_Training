[["index.html", "An R Training Resource 1 Introduction", " An R Training Resource Skills England Analysis and Insight 2025-07-18 1 Introduction This book was produced to help SEAI colleagues and interested people to learn R. Its contents cover key features of the R programming language and R studio, with specific focus on the tools and skills used in (economic) analysis. I have drawn from lots of existing sources and distilled much of that information into chapters demonstrating how I like to use R. There is no specific data used, as the aim of this tool is to provide principles which extend beyond a single dataset and the chapters aim to elucidate skills used to analyse and make sense of that data. Since its inception, the contents have been broadened to include code that is more generally applicable and most updates have been done in my own time, using this as a personal code and best practice repository. For any questions, suggestions or if you would like to make a contribution, please contact: Abdus-Subhaan Karim abdus-subhaan.karim@education.gov.uk External resources (this is not an exhaustive list and click the text to use hyperlinks) AI and other large language models. Use these to write, check and optimise code. Hadley Wickham’s R for Data science book DfT’s R cookbook ESFA’s R cookbook R cheat sheets Stack Overflow (for questions tagged ‘R’) Swirl learn R in R Search Engines YouTube Datacamp R Graph Gallery A starting point for ALL your graphical needs. Econometrics help Python resources I recently discovered this book, which is similar to the R cookbook but for Python. Python DfE Internal resources There are R various R resources held within DfE. none of these links will not work unless on a DfE server These include: DfE’s Analytics Academy - this is a comprehensive course which goes far beyond the code contained in this book. There are videos and tasks using DfE data. DfE git guidance ESFA git and R training DfE Devops training DfE Analytical Community Data Camp License Notes These chapters assume some minimal prior understanding of R i.e. what it is; how to download R studio/set it up; and what some of its capabilities are. If you have never used R before, you might want to engage in some other materials first. As with any coding language, there are many different ways to achieve the goals that we cover in this book. How you go about tackling any problem a personal choice. The code I present here aims to provide a basis from which you can iterate and probably improve. If you know of better or different methods to those you read, please do share them so that others can benefit from your knowledge. "],["Basics.html", "2 Basics of R 2.1 R and R studio 2.2 Files 2.3 R Projects 2.4 R Studio’s Panes 2.5 Packages 2.6 Data types 2.7 Data structures 2.8 Quiz: R Basics", " 2 Basics of R To make sure you have the most up-to-date version of R, run this code: if(!require(installr)) { install.packages(&quot;installr&quot;); require(installr)} #load / install+load installr # using the package: updateR() 2.1 R and R studio R is a programming language just like Python and javascript. Many of it’s applications are used for statistics, modelling and working with data. R studio is an integrated development environment (IDE) where you can use the R programming language (as well as Python). It supports writing in the language, executing code, file management, version control etc. It is a good way to code in R. You can use other programmes to code with R, such as Visual Studio (though you might need an extension). I recommend using R studio and this book will all guide through the use of R in this IDE. 2.2 Files This chapter focuses on working with R scripts. File type: &lt;File_Name.R&gt;. There are numerous different types of files and projects you can work with in R, including markdowns, bookdowns, presentations and shiny apps. Different file types have their own suffixes. R files end in .R; RMarkdown files end in .Rmd; text files end in .txt etc. As with any work, how you save and document your work is a choice. Depending on the objective, different approaches might be taken. For basic data analysis you have two main options, both of which are valid. You can just open an R script, save it in a file location and work from there. You will need to tell the R script where it is saved by setting your working directory. This is fine for ad hoc bits of work, but for bigger things, you should use R projects 2.3 R Projects Projects act as a way to group your scripts and therefore separate out your work strands. When you open a project, the files pane will automatically open up as where the project is saved. This then allows you to see all of your files. To create a project, click file + new project. To create a script within this project, click file + new file + R script. Projects also enable version control through git and devops. In order to learn about these, see the stats production guidance on git, the ESFA guidance on git and the analytics academy videos on git. More on this later. Projects sit in a specified file location, and enable a user to work with multiple files within (/below/behind) where that project is saved. When working in R, the project you have open can be seen in the top right of the pane. In order to pull in data and work interactively with other scripts, you need to tell R which working directory these files are in, so it knows where to look. Once setting your working directory you can work across other files as stated above. If you are unsure of what this means, run (in either the console or a script) this code: getwd() #this code will tell you the file path you are currently working in If your working directory is not where the project is saved, setting it to that path is usually a logical way to start. For example: setwd(&quot;C:/Users/username(akarim as an example)/OneDrive - Department for Education/Skills England/R Projects&quot;) You can tab across after the forward slashes to find a file location or, alternatively, paste a file location from your file explorer. Important to note is that R reads forward slashes and backslashes differently to the file explorer. A file path in R generally requires forward slashes (or double backslashes). To normalize a file path that you’ve copied directly from an explorer window, you can use the function normalizePath() or readClipboard() with the copied file path. There are two ways to define paths to a file or directory: Relative paths which find a location from an existing location, rather than the root of the file system. Relative paths cannot, therefore, span different drives. Absolute paths which are defined by including an entire path from the root directory Having set your file location, you can then navigate and source files from anywhere within that file location. Relative paths can be coded using /, ~ and ... For more information see this web page The most common usage of relative pathing will be using .. to navigate upwards and / to navigate downwards. Say your working directory is: //vmt1pr-dhfs01/Working/HE-EAT-WKG-FS/Graduate Outcomes, but you wanted to access a file in the Working folder, 2 sub-folders above the Graduate Outcomes folder, you could navigate here with 2x ..s: source(&quot;../../example_folder_name&quot;) Another way to do this would be to set your working directory to that folder, access the file, then reassign the working directory to where it was before. 2.4 R Studio’s Panes The R Studio window splits up into four quadrants, which can be dragged and adjusted depending on what you wish to focus on. Each pane has different functions, the basics of which are covered below. Left hand side: Where you run and store code. Code can be run by highlighting the code in a script (top left) and pressing ctrl + enter, OR by writing it in the console (bottom left) and pressing enter. The ‘Run’ button at the top right of the source pane will also execute code. Usage: code that you want a record of and might want to re-run at any time should be written and run in scripts (the source). Code that you do not need to save can be written in the console. Things like getwd() or data exploration functions are, therefore, usually written in the console. If you want to install a package, do a quick calculation or look up a function’s documentation, you could put these in the console. Most things are probably better for writing in scripts, though. Right hand side Your files will show up in the files pane in the bottom right. Also this for viewing plots (all plots are stored behind each other in the plots tab, if you want to navigate between old and new plots you’ve produced). The help bar is also contained in the bottom right pane. If you are ever unsure about the documentation or application of a function, package or command you can run: ?function_name() the helper will then appear. The environment (top right) is where all the objects, values and functions you create will sit. Also, if you’ve connected to a server, this connection will appear in the connections tab. Your history is stored in the history tab. You want to clear the environment semi-regularly, so that you are not interacting with or using objects that do not exist if you re-run your code. They might have been removed or created in a way that does not create the proper object if you were to re-run your code from start to end. Set your global options to never save ,RData on exit. Do this by clicking tools + global options + general. To see all the items in the environment use ls() To remove an item use # remove 2 objects rm(object_name1, object_name2) # remove all objects except df1_to_keep and df2_to_keep rm(list=setdiff(ls(), c(&quot;df1_to_keep&quot;, &quot;df2_to_keep&quot;))) 2.5 Packages R uses packages and functions to enable you to work efficiently. BaseR is pre-installed. It contains basic functions to assign objects, create ‘if’ statements, add two numbers together, create lists etc. Additionally, because R is an open source programme, developers have built other packages that you can install and load into R. These packages contains functions and functionality which can make coding easier and more efficient. Any uninstalled package needs to be installed first: install.packages(“package_name”) Once a package is installed, its functionality can be used by loading it into your project library(installed_package_name) To load my packages at the start of a project, I link to a script with this code in. The pacman::p_load function loads packages if they’re installed already, installs them then loads them if not. The set of packages are the core ones I use in lots of work I do. You might want to add or take others out. if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) #this will load the pacman package pacman::p_load(dplyr, #the :: specifies to use the p_load function from the pacman package. Some functions are named identically in more than one package; this ensures you use the correct one. data.table, stringr, stringi, tidyverse, stats, openxlsx) #add any packages to this list If any packages cannot be installed, you might be using an outdated version of R. To update it: # Run this to install &quot;updateR&quot; if(!require(installr)) { install.packages(&quot;installr&quot;); require(installr)} #load / install+load installr # use the package to update your R: updateR() 2.6 Data types R has various data formats and types. Working with R, it is important to appreciate that there are nuances between data types. They are useful for different things, and get called in different ways. R has 6 basic data types. character: “a”, “swc” numeric: 2, 15.5 integer: 2L (the L tells R to store this as an integer) logical: TRUE, FALSE complex: 1+4i (complex numbers with real and imaginary parts) raw Sometimes you will need to transform the data type. For example, if numbers are stored as characters. This will prohibit mathematical functionality. To convert between data types, use as.numeric, as.logical and others as functions or as arguments within other functions. The most basic example to change a column’s data type mutate(example_column = as.numeric(example_column)). Be careful when converting text to numbers, as.numeric will return “NA” if you try to convert “6,377” to 6377, because of the comma. To get around this, consider string manipulation functions from the stringi or stringr packages, or readr::parse_number. For more examples of changing data structures see the data manipulation chapter or the (more advanced) 2.7 Data structures R has many data structures. These include: data frame vectors (atomic vectors are vectors with one type of data) factors matrix list R is generally used to work with data and objects, especially in the most rudimentary uses (which is what we are covering in this chapter). In order to do this, you usually load external data - e.g., from excel files or SQL servers - though you could also encode objects and data yourself from scratch. The sections below show how to load and explore objects in R. 2.7.1 Data Frames A data frame is an array of rectangular data (which makes it easy to manipulate). Any table you load in correctly from excel will be stored as a data frame. For the purposes of exploration below, we will load in the iris dataset. This is pre-loaded to R. We can explore the data using functions in BaseR data(&quot;iris&quot;) # it is a data frame with 5 variables (columns) and 150 observations (rows) # to load the data, just type iris into the console and hit enter # what tyoe of object is iris? class(iris) # tells us it is a data frame [1] &quot;data.frame&quot; # How many rows does the data frame have? nrow(iris) [1] 150 # How many elements are in the data frame? length(iris) [1] 5 # what are the column names? names(iris) [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; &quot;Species&quot; # What are the unique variables in the species column? unique(iris$Species) # These are stored as a factor with 3 levels [1] setosa versicolor virginica Levels: setosa versicolor virginica # What is the structure of the data. What are the variable types? str(iris) [1] &#39;data.frame&#39;: 150 obs. of 5 variables: $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ............. $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... # Open the data frame in a pane. You can hover over the column index, column title and see the data structure and range View(iris) # see if you have any duplicates in the data duplicates_df &lt;- iris %&gt;% group_by(Sepal.Width) %&gt;% filter(n() &gt; 1) 2.7.2 Vectors A vector is a sequence of data elements. Vectors will contains elements of the same type or will convert the elements implicitly. In a vector, the order matters. If you think mathematically, R reads a vector in order. This is one way a vector is distinguished from a list We can use the assign syntax &lt;- c() to assign vectors x &lt;- c(1, 2, 3) #R will create an vector, x, with 3 numeric elements x1 &lt;- c(1, 2, 3, &quot;4&quot;) #R will read all elements as characters because we specified that 4 is a character y &lt;- c(10, 100, 1000) z &lt;- x * y # vectors can be multiplied vectors can also be character strings GO_Team &lt;- c(&quot;Sarah&quot;, &quot;Abdus&quot;, &quot;Yilan&quot;) GO_Team[2] #this it the element in position 3 [1] &quot;Abdus&quot; You can add and remove elements from vectors # create a vector of the numbers 1,2,3,4 n4 &lt;- c(1:4) # add the number 5 to the vector n5 &lt;- append(n4, 5) # removing objects from a vector # define a %notin% function `%notin%` &lt;- Negate(`%in%`) # remove 4 and 5 from the n5 vector and assign it to n3 n3 &lt;- n5[n5 %notin% c(4,5)] 2.7.3 Factors A factor is essentially a vector of n integer values with a corresponding set of character values. The only input argument you need to specify is a vector of values from any atomic (same data) type, and the factor function will return a vector of factor values. This relates to the concept of levels, where the level of a factor is basically the number of distinct elements, in reverse order to how they are written. You can specify the levels if you wish to change the order. Employee_Of_The_Week &lt;- factor(c(&quot;Abdus&quot;, &quot;Abdus&quot;, &quot;Abdus&quot;, &quot;Abdus&quot;, &quot;Sarah&quot;), ) #creates a factor in the global environment. You can specify the order of the levels. If not specified, R will do this automatically (in reverse to the order they appear) print(Employee_Of_The_Week) # [1] Abdus Abdus Abdus Abdus Sarah # Levels: Abdus Sarah # You could specify the levels with a levels = argument. E.g. levels = c(&quot;Abdus&quot;, &quot;Sarah&quot;) levels(Employee_Of_The_Week) # the levels are the order in which the elements appear Employee_Of_The_Week[5] #this returns the element in position 5 of the factor Factor levels are important when you need to specify the order of something e.g. to arrange graphs by High , Medium, Low, Specialist, this uses a tariff vector x &lt;- c(\"High\", \"Medium\", \"Low\", \"Specialist\") as the levels for turning the tariff column into a factor. 2.7.4 Matrices Matrices are used in regression analysis and other more complex data exercises, but not much in the standard outputs we produce. A matrix is a collection of elements of the same data type (numeric, character, or logical) arranged into a fixed number of rows and columns. Matrix1 &lt;- matrix(1:8, 2, 4) # this creates a matrix of the numbers 1 to 8, in 2 rows and 4 columns. It fills down from column 1 and then column 2, such that the number 3 is the in position [1,2] 2.7.5 Lists Lists hold different types of data i.e. character, numeric and integers and data frames in a single list. You can access the elements of this list with square brackets [] or the dollar sign $ list_example &lt;- list(1, 2L, &quot;3&quot;) # here 1 is stored as a number, 2 an integer and 3 a character. You can also house multiple objects within a single name in the global environment, which could make accessing analysis tidier. # create an element, Int_SNs, which houses 2 sheets of data: England_SNs and Scotland_SNs Int_SNs &lt;- list(England_SNs = readxl::read_xlsx(&quot;SNs.xlsx&quot;, sheet = &quot;England&quot;), Scotland_SNs = readxl::read_xlsx(&quot;SNs.xlsx&quot;, sheet = &quot;Scotland&quot;)) # extract the england df from the list of international dfs England_SNs &lt;- as.data.frame(Int_SNs[England_SNs]) 2.8 Quiz: R Basics 2.8.1 Test Your Understanding ## **1. What function sets your working directory in R?** ## ## A) set_directory() ## B) getwd() ## C) working_dir() ## D) setwd() ## ## **2. Which function loads an already installed package?** ## ## A) install.packages() ## B) library() ## C) load() ## D) require_package() ## ## **3. What data type is TRUE in R?** ## ## A) character ## B) numeric ## C) logical ## D) integer ## ## **4. What keyboard shortcut runs highlighted code in R Studio?** ## ## A) Ctrl + R ## B) Ctrl + Enter ## C) Alt + R ## D) Shift + Enter ## ## **5. What does getwd() do?** ## ## A) Gets working directory ## B) Gets working data ## C) Gets window details ## D) Gets workspace ## ## **6. Which symbol is most commonly used for assignment in R?** ## ## A) = ## B) &lt;- ## C) := ## D) -&gt; ## ## --- ## ## **Answers:** ## ## 1. D ## 2. B ## 3. C ## 4. B ## 5. A ## 6. B 2.8.2 Interactive R Code Exercises Try these coding exercises in your R console: # Exercise 1: Create a vector of numbers 1 to 10 # Your answer: # Exercise 2: Load the ggplot2 package # Your answer: # Exercise 3: Set your working directory to your Documents folder # Your answer: # Exercise 4: Create a logical vector with TRUE, FALSE, TRUE # Your answer: # Exercise 5: Get help for the mean function # Your answer: 2.8.3 Self-Check Questions Answer these questions for yourself: True or False: R is case-sensitive Fill in the blank: The function ____() removes objects from your workspace Multiple choice: Which function shows the structure of an object? str() structure() show() display() ## **Self-Check Answers:** ## 1. TRUE - R is case-sensitive ## 2. rm() - removes objects from workspace ## 3. A) str() - shows structure of objects "],["Functions.html", "3 Syntax and Functions 3.1 Syntax 3.2 BaseR Functions 3.3 Quiz: R Syntax and Functions", " 3 Syntax and Functions 3.1 Syntax R is its own programming language, and some of the key syntax is not necessarily intuitive. We have covered some already, but here follows some important things to know: Use &lt;- to assign variables e.g. x &lt;- 1 A shortcut to producing is pressing the Alt + - keys together. Use c() to combine (i.e. to create) a vector. e.g. c(1,2) Use == to evaluate something as being exactly equal to 1 = 1 #this will return an error 1 == 1 #this will return: [1] TRUE Use %in% to specify that a character string or other data element is contained in some data structure. 1 %in% c(2, 2, 1) # this will return [1] TRUE as 1 is in the vector we&#39;ve defined Use != to specify “is NOT equal to” 1 != 2 #this will return [1] TRUE as 1 is NOT equal to 2 Use :: to specify that a function comes from a specific package. This is necessary if you have two packages which include functions with the same name. # load the stringr package library(stringr) stringr::str_split(&quot;Let&#39;s split this string into 10 elements separated by spaces&quot;, &quot; &quot;) #this uses the str_split function from stringr [1] &quot;Let&#39;s&quot; &quot;split&quot; &quot;this&quot; &quot;string&quot; &quot;into&quot; &quot;10&quot; &quot;elements&quot; &quot;separated&quot; &quot;by&quot; &quot;spaces&quot; Use %&gt;% from the Dplyr package - the pipe - to apply multiple functions to an object in turn. As words, the sequence would read “… and then”. Use Ctrl + Shift + M as a keyboard shortcut to produce the pipe. library(dplyr) y &lt;- 25 #define y as the number 25 x &lt;- y %&gt;% #define a new element, x, as 25. Insert the pipe to continue the code chunk on our object, x. sqrt() %&gt;% # square root our element, x. *we do not need to specify that we&#39;re square rooting x as it&#39;s within a pipe print() #print the object we&#39;ve created then manipulated [1] 5 Use ~ (tilde) to define the relationship between two sides of an equation. It separates the left and right side two_by_two &lt;- c(1:4) #this creates a vector of the numbers 1 to 4: 1,2,3,4 print(two_by_two) [1] 1 2 3 4 Even_numbers &lt;- case_when(two_by_two%%2 == 0 ~ &quot;divisible by 2&quot;, # when the element in our two by two vector is divisible by 2, assign the text &quot;divisible by 2&quot; TRUE ~ &quot;not divisible by 2&quot;) #when our first condition is not met, assign &quot;not divisible by 2 print(Even_numbers) [1] &quot;not divisible by 2&quot; &quot;divisible by 2&quot; &quot;not divisible by 2&quot; &quot;divisible by 2&quot; #this will create a vector of 4 character strings, which correspond to the two_by_two vector. Those in position 2 and 4 (the numbers 2 and 4) are divisible by 2, so returns &quot;divisible by 2&quot;. Use parentheses () to pass argumnts to a function Use $ to subset an object, similar to square brackets. Use square brackets [] to grab a subset of data. It appends an index vector to a specified vector. Square brackets can usually be applied in place of $, and are more maleable to the specific task, though they might be slightly less intuitive. See the example below. For more detailed explanation of extracting/subsetting variables see the data manipulation chapter data(&quot;iris&quot;) # load the iris data unique(iris$Species) #show the unique entries in the Species column within the iris data frame [1] setosa versicolor virginica rep(unique(iris$Species), times = 2) # repeat x2 the unique entries from the Species column within the iris data frame [1] setosa versicolor virginica setosa versicolor virginica rep(unique(iris[[5]]), times = 2) #repeat x2 the unique entries from the 5th column within the iris data frame: the species column [1] setosa versicolor virginica setosa versicolor virginica Use {} to evaluate a series of items within the environment of the brackets. More on this when we discuss functions. (Advanced) use {{}}, := and !! when defining functions and needing to specify the nature of objects within them. More on this in User-defined Functions chapter 3.2 BaseR Functions Functions are key to coding efficiently and effectively. BaseR, R’s language, contains many functions. Packages also contain specific functions that improve on the inbuilt functionality of R. These functions speed up and optimise your code. To see the function inputs, run ?function(). The help window will appear in the bottom right panel. You can also tab across from the open bracket once writing the function to see the arguments. 3.2.1 Base R and Inbuilt Functions ?() get help on functions specified after the question mark. e.g. run ?rm() rm() removes a specified object from the global environment. This can also be applied to the whole environment with the brush icon. nrow() how many rows are in a data frame nchar() how many characters are in a string gsub(pattern, replace, x) replaces matches in x with a string. Also see stringr and stringi packages for string manipulation. paste() concatenate vectors paste0() concatenate strings is.na() is missing !is.na() is not missing is.null() is null 3.2.2 Programming functions If statements The most important thing to remember with if else statements is to make sure the else is on the same line as the close curly bracket of the if statement. Otherwise the else won’t be tied to the preceding condition. if (condition){ #Do something } else { #Do something different } i &lt;- 3 if (i &gt; 3){ print(&quot;yes&quot;) } else { #because the function is continuous, the else needs to be on the same line as the final curly bracket of the if function. print(&quot;no&quot;) } [1] &quot;no&quot; Adding conditions to if statements using else if i &lt;- 2 if (i &gt; 3){ print(&quot;greater than 3&quot;) } else if ( i == 3) { print(&quot;equal to 3&quot;) } else { print(&quot;less than 3&quot;) } [1] &quot;less than 3&quot; Loops are a good and easily comprehensible way to optimise your code, but take a bit of time to effectively apply to your work. More detail is contained in the User-defined Functions chapter. For loop #Generic for(variable in something) { do something } #Example application for (i in 1:4){ j &lt;- i + 10 print(j) } [1] 11 [1] 12 [1] 13 [1] 14 While loop #Generic while(condition){ #do something } #Example application i &lt;- 1 while (i &lt; 6) { print(i) i = i+1 } [1] 1 [1] 2 [1] 3 [1] 4 [1] 5 3.3 Quiz: R Syntax and Functions ## **1. How do you test if a value is &#39;exactly equal to&#39; another in R?** ## ## A) &lt;- ## B) = ## C) == ## D) %in% ## ## **2. What is the purpose of the `%in%` operator?** ## ## A) To perform integer division ## B) To check if an element is contained in a vector or list ## C) To multiply matrices ## D) To assign a value ## ## **3. Which syntax is used to call a function that comes from a specific package?** ## ## A) package$function() ## B) function(package) ## C) package-&gt;function() ## D) package::function() ## ## **4. In the context of the `dplyr` package, what does the pipe operator `%&gt;%` do?** ## ## A) It subtracts one value from another ## B) It creates a plot ## C) It passes the object on its left to the function on its right ## D) It stops the execution of the code ## ## **5. What is the primary use of the tilde `~` operator in R?** ## ## A) To approximate a number ## B) To define the relationship between variables in a formula ## C) To negate a logical statement ## D) To specify a user&#39;s home directory ## ## **6. Which function is used to remove a specified object from your R environment?** ## ## A) remove() ## B) delete() ## C) rm() ## D) clear() ## ## --- ## ## **Answers:** ## ## 1. C ## 2. B ## 3. D ## 4. C ## 5. B ## 6. C "],["reading-in-data.html", "4 Reading in Data 4.1 Good practice 4.2 Reading in .csvs and excel workbooks 4.3 SQL 4.4 Quiz: Reading in data", " 4 Reading in Data One of R’s best applications is for manipulating and analysing data. However, R doesn’t have a store of data (aside from some basic pre-loaded datasets). We need to save this outside the R environment and then load or read it into R. Our data tends to be stored in excel files - either workbooks or .csvs - or SQL databases. You can also read in data from Stata and other programmes. Use Google to find packages that allow you to read in this data, if this is how your data is stored. This section uses 3x Higher Education-focused examples of reading in data. If you set your working directory as per the code below, you will be able to read in the data files being used. 4.1 Good practice As shown below, documentation is essential. For example, if you download data from NOMIS and delete the 10-12 rows of table identifiers, a future analyst or QA analyst will struggle to identify the source of the data, or to verify that filters are correct. Equally, with any other data source, if you do not include very clear links to the source, [if relevant] when it was accessed, [if relevant] where from within that source the data come, then it is impossible to verify the source data. It is good practice to store this information at the top of a document; in a log of input data; or within your code. 4.2 Reading in .csvs and excel workbooks You can read in data using the whole file URL or from a relative file path, using your current working directory as a root. A reminder of how to check your directory is below. Refer to section 2.2: R Projects for more detail. getwd() #if your directory is not where it needs to be to load data or source a file, set it #Alternatively, you can navigate through to the relative path, as long as the location is on the same drive. setwd(&quot;&quot;) 4.2.1 .csvs The read.csv() function is pre-loaded into R through the utils package. We will usually want to assign the loaded data to an object, so that we have it stored in our global environment. AN APS data file on csv is downloaded from NOMIS which has employment figures for 412 4-digit SOC codes. It is saved in the project’s data folder. I have done nothing to the file other than save it as a UTF-8 comma delimited .csv file. The first 16 rows of the HESA data contain unique identifiers, details about the source and file specification, which can be referred back to. Employment_by_SOC_Mar_25 &lt;- read.csv(file = &quot;Data/Occupation_employment_figures_Mar_2025_4_digit_SOC.csv&quot;) BUT reading this in will create a data frame with lots of blank values, missing column titles and irrelevant rows. Because the top 13 or so rows are useful for documentation and finding the data source, we want to keep these in the .csv file, but we don’t want R to read them into R, so we tell the read.csv function to skip them. Employment_by_SOC_Mar_25 &lt;- read.csv(file = &quot;Data/Occupation_employment_figures_Mar_2025_4_digit_SOC.csv&quot;, skip = 13) If we want the column names exactly how they appear in the data, we can add the check.names = FALSE argument. When referencing these columns, you will need to put the name inside tilted apostrophes in order to tell R that the object has spaces in it, otherwise R will read a single column heading as many, and you will get an error. This is why it is common to use underscores when naming objects and variables Employment_by_SOC_Mar_25 &lt;- read.csv(file = &quot;Data/Occupation_employment_figures_Mar_2025_4_digit_SOC.csv&quot;, skip = 13, check.names = FALSE) %&gt;% rename(&quot;occupation_soc_code_label&quot; = 1) # renaming empty column Now we have a rectangular dataset with non blank values and the column names we want. But when we check the data format, we find that data has been read in as character data. We can see this with str(Employment_by_SOC_Mar_25) You can change this by selecting which columns you want to be numeric. We want columns 2 and 3 to be numeric. If you simply specify that you want them as.numeric, R will turn the values with commas into NAs. One way to avoid this is using readr’s parse_number function from the readr package. # load readr library(readr) # create a new object with columns 3 to 27 now numeric Numeric_Employment_by_SOC_Mar_25 &lt;- Employment_by_SOC_Mar_25 %&gt;% mutate_at(2:3, readr::parse_number) # check the structure of the data str(Numeric_Employment_by_SOC_Mar_25) # we can now see that columns 2 and 3 are numeric You can now explore the data as shown in segment 2.5.1 - Data Frames In some cases, R might create funky column headings. Some options for solving might include use fileEncoding = \"UTF-8-BOM\" as an argument within the read.csv function check the source data Some other examples of making data numeric or replacing NAs with 0 mutate(across(-c(`SOC Code`), ~as.numeric(.x))) mutate(across(-c(SOC_label), ~ readr::parse_number(.x))) mutate(across(everything(), ~replace_na(., 0))) # remove rows where all values are #N/A filter_at(vars(everything()), all_vars(!is.na(.))) 4.2.2 Large .csvs The fread() function is faster than read.csv, but has less flexibility. 4.2.3 Excel workbooks It might be that you want to store lots of sheets in a single workbook, and want to read in a particular sheet. It also might be that you want to do some manipulation in excel first, then want to read in outputs that have had calculations applied. If you do this, I would advise locking the sheet so that no more changes can be made. Add a “READ ME.txt” file to the folder containing the password to unlock the sheets, or stick it in a sheet at the start of the workbook. Changes will affect the data when re-read into R, post-changes. .csv files are saved as comparabily small files, with no formulas or calculations, just cell values. If you need to save these cell formulas then an excel workbook will probably be preferable. The read_excel function comes from the readxl package library(readxl) # Example # Assuming you have a file with multiple sheets Sector_employment_figures &lt;- read_excel(path = &quot;Data/Multiple Sector sheets workbook.xlsx&quot;, sheet = &quot;Creative Industries&quot;, range = &quot;A17:AA237&quot;) 4.3 SQL SQL databases are a common and secure way to store data. SQL data can be loaded into R. Equally, SQL code can be run within R studio (you can tell your script to translate the code into R code, effectively). Data exploration of SQL is much faster and more efficient if done in the SQL programme itself. The applications below show how to load data from DfE SQL servers. The code will not work without access to the data. 4.3.1 Connecting to databases library(odbc) con &lt;- dbConnect(odbc(), Driver = &quot;SQL Server&quot;, Server = &quot;T1PRMDRSQL\\\\SQLPROD,55842&quot;, Database = &quot;PDR&quot;, Trusted_Connection = &quot;yes&quot;) 4.3.2 Loading data into R # download the data # instead of &quot;Tier 1&quot; this argument might be whatever is before the full stop in front of the table name when shown in SQL. For UCAS data, for example, this is &quot;dbo&quot; KS4_data &lt;- tbl(con, in_schema(&quot;Tier1&quot;, &quot;KS4_Pupil_MasterView&quot;)) # it is best to apply filters at this stage to improve efficiency and minimise the amount of data that R needs to extract students &lt;- KS4_data %&gt;% select(URN, PupilMatchingRefAnonymous, FSM6CLA) %&gt;% collect() 4.3.3 Running SQL Queries # run a query from the connection established (as shown above) # put a query in quotation marks # An example query has been left in quotation marks for clarity output_data &lt;- dbGetQuery(con, &quot; select distinct [Postcode], [Quintile] from [HE-AN-DATA-NS].[Geography].[OfS_POLARPostcode] where [Measure] = &#39;Polar4_quintile&#39; &quot;) 4.4 Quiz: Reading in data ## **1. When using the read.csv() function, which argument tells R to ignore the first 13 rows of the file?** ## ## A) ignore = 13 ## B) header = 13 ## C) skip = 13 ## D) omit = 13 ## ## **2. What is a common issue when R reads a column containing numbers with commas (e.g., &#39;1,500&#39;)?** ## ## A) R automatically converts it to a numeric value without the comma. ## B) R reads it in as a character or factor data type. ## C) R returns an error and stops the import. ## D) R converts the comma to a decimal point. ## ## **3. Which function from the `readr` package is specifically recommended for converting strings with commas into numbers?** ## ## A) as.numeric() ## B) parse_number() ## C) convert_to_numeric() ## D) mutate_at(..., as.numeric) ## ## **4. Which package provides the `read_excel()` function to import data from Excel workbooks?** ## ## A) utils ## B) odbc ## C) readr ## D) readxl ## ## **5. When using `read_excel()`, which argument do you use to specify the name of the sheet you want to read?** ## ## A) tab = ## B) worksheet = ## C) sheet = ## D) select = ## ## **6. Which function is used to establish a connection to a SQL database using the `odbc` package?** ## ## A) dbConnect() ## B) odbc_connect() ## C) dbGetQuery() ## D) sql_open() ## ## --- ## ## **Answers:** ## ## 1. C ## 2. B ## 3. B ## 4. D ## 5. C ## 6. A "],["creating-outputs.html", "5 Creating outputs 5.1 Writing .csvs 5.2 Saving objects 5.3 Saving graphs 5.4 R Markdown 5.5 Presentations 5.6 Other links 5.7 Quiz: Outputs", " 5 Creating outputs R is great for manipulating data and generating graphs, tables or reports. BUT R Studio is usually not where these outputs are best viewed or used by the people for whom they are created. R allows you to export the objects you have generated into accessible formats, the most general ones being: Tables to .csv files Images/Graphs to .JPEG or .PDF files Reports (RMarkdowns) to .html, .PDF or word documents Reports to presentations (see packages to do this in markdown) Reports to books (RBookdowns) Dashboards This Chapter will focus on the basics: saving graphs and tables.The online resource are plentiful if you know what you’re looking for. There are also chapters in DfE’s analytical academy. Outputs such as shiny apps are beyond the scope of this resource. 5.1 Writing .csvs This is the most common way to export tables that we have created or manipulated. Excel is more user-friendly than R for viewing data tables. Additionally, if you need to put a table into a MS word report, you might want to export it as a .csv as these are easier to copy and format (such as with colour, bolding or cell merging) prior to inserting the table into your word document. Once again, writing a .csv is dependent on your working directory. You need to set this somewhere proximate to the folder you intend to write the .csv into. Otherwise you could paste a whole file path URL int the file = argument data(&quot;iris&quot;) # we can write the iris data as a .csv in our outputs folder write.csv(x = iris, file = &quot;Outputs/iris_data.csv&quot;, row.names = FALSE) This creates a .csv file in the Outputs folder called “iris_data”. By specifying that row.names = FALSE, the .csv will not have numbers 1:150 in the first column of the output file. 5.1.1 Writing multiple outputs as sheets of an excel file This video shows you how to do this library(xlsx) library(openxlsx) # step 1: load relevant packages # step 2: complete analysis as usual, giving each output a name (i.e. using R_Output_1_Name &lt;- ) # step 3: use the following code to pull together Excel_File_Name &lt;- list(&quot;Sheet_Name_1&quot; = R_Output_1_Name, &quot;Sheet_Name_2&quot; = R_Output_2_Name) write.xlsx(Excel_File_Name,&quot;./Excel_File_Name.xlsx&quot;,overwrite = TRUE) 5.2 Saving objects A good tip for reducing markdown (or other output) running speeds is to save your rendered objects and then read them into the markdown when you knit it, rather than sourcing all of the code. Graphs can be saved as .RDS objects so that when you read them in, they retain all of their underlying features, e.g., text labels, so that you can render them as interactive charts. Similarly, regression outputs can be saved with all the underlying data, so you can work with and manipulate them (e.g., extract particular values or present in a custom way). You use readRDS() to read the object back in. # example of saving an object saveRDS(Object_Name, &quot;Object_Name.Rds&quot;, version = 2) 5.3 Saving graphs After creating a graph, the best way to store the output is in a markdown or other feature of R that will update the rendered image if any of the inputs or code change. For ad hoc work, though, we might simply want to export an image. To do this we can either: Create the plot, then click export (in the bottom right “viewer” panel) and save as either a PDF or JPEG Iris_Scatter &lt;- plot( x = iris$Petal.Length, y = iris$Petal.Width ) Create a JPG/PDF with a line of code, then plant the plot into it #create the pdf pdf(&quot;Outputs/iris_scatter.pdf&quot;, width = 8, height = 7, paper = &quot;A4&quot;) #create the plot in the pdf Iris_Scatter &lt;- plot( x = iris$Petal.Length, y = iris$Petal.Width ) #close the pdf dev.off() # The JPEG arguments are very similar to those for a pdf # jpeg(filename = &quot;Outputs/iris_scatter.jpg&quot;, width = 500, height = 500) You can also open plots and screenshot these if necessary. 5.4 R Markdown This is the bible for markdown. This link is good for basics. I have started trying to store all outputs from a project in an outputs summary markdown (.rmd) so that other analysts can see exactly what is created, and what the objects used to do this are. A common format is shown below. You can also browse this theme gallery or google R markdown themes to see various default option styles. These would sit in place of the flatly argument below. A more generic gallery of output formats that can be rendered through markdown are in the R markdown gallery --- title: &quot;Outputs for Recruitment limits IA and EQA&quot; author: &quot;Tom Harris&quot; date: &quot;`r Sys.Date()`&quot; output: html_document: theme: flatly toc: true toc_float: true --- &lt;style type=&quot;text/css&quot;&gt; body{ /* Normal */ font-size: 14px; font-family: &quot;Segoe UI&quot;; font-size: 1.75em; } h1 { /* Header 1 */ font-size: 31px; } h2 { /* Header 2 */ font-size: 25px; } h3 { /* Header 3 */ font-size: 21px; } code.r{ /* Code block */ font-size: 12px; } pre { /* Code block - determines code spacing between lines */ font-size: 14px; } &lt;/style&gt; &lt;style&gt; div.border {border-style: solid; border-color:#D6DCE5;background-color: white; text-align: center; border-radius: 5px; padding: 10px;} &lt;/style&gt; &lt;style&gt; div.blue {background-color:#D6DCE5; border-radius: 5px; padding: 12px;} &lt;/style&gt; Most markdown features are very intuitive. They can be googled very easily. For tabs, use {.tabset} and {.tabset .tabset-pills} with headings to define levels. You could just get rid of the ## Heading 1 line and have a single tier of tabs. See below example. The functions would need to be included as code chunks, rather than headings, but are shown together here for concision. ## Sector FTE growth {.tabset .tabset-pills} ### Sector numbers {tabset} #### FTE graph ggplotly(sector_FTE_graph, tooltip = &quot;text&quot;) #### Underlying Table kableExtra::kable(sector_growth, format = &quot;pipe&quot;) ### Tariff numbers{.tabset} #### FTE graph ggplotly(tariff_FTE_graph, tooltip = &quot;text&quot;) #### Underlying Table kableExtra::kable(tariff_growth, format = &quot;pipe&quot;) 5.5 Presentations You can use R markdown to create presentations. These allow interactivity. They can also enable your presentations to automatically update when the analysis does. There are some examples of presentations in the R markdown gallery. Xaringan is also a useful and very flexible package. Writing presentations is quite complicated and there isn’t much value in this book just having a few bits and bobs. Below are some good links to places with more detail. Kate Jolly’s blog Xaringanthemer documentation Xaringan themes github 5.6 Other links Unsplash.com is great for downloading free, high resolution images. 5.7 Quiz: Outputs ## **1. When using write.csv(), what does the argument `row.names = FALSE` do?** ## ## A) It removes the column headers from the output file. ## B) It prevents R from writing the default numbered rows into the first column of the .csv file. ## C) It saves the file without any row data, only headers. ## D) It prompts the user to enter row names manually. ## ## **2. According to the script, which package is mentioned for writing data to multiple sheets in a single Excel workbook?** ## ## A) readr ## B) writexl ## C) openxlsx ## D) data.table ## ## **3. What is the primary benefit of saving an R object (like a graph or model) as an .RDS file?** ## ## A) It saves the object as a plain text file that is easy to read. ## B) It allows you to read it back into R later, preserving all its features and underlying data. ## C) It automatically converts the R object into a .csv file. ## D) It makes the R object smaller in file size than any other format. ## ## **4. Which function do you use to read an object that was saved with `saveRDS()` back into your R session?** ## ## A) loadRDS() ## B) openRDS() ## C) getRDS() ## D) readRDS() ## ## **5. When saving a plot to a PDF file using code, which function must you call *after* creating the plot to finalize and close the file?** ## ## A) pdf.close() ## B) close.device() ## C) dev.off() ## D) save.plot() ## ## **6. In an R Markdown YAML header, what does the `toc: true` argument achieve?** ## ## A) It automatically generates a table of contents based on the document&#39;s headers. ## B) It styles the output document with a specific theme. ## C) It checks the R code for errors. ## D) It allows the table of contents to float on the side of the page. ## ## --- ## ## **Answers:** ## ## 1. B ## 2. C ## 3. B ## 4. D ## 5. C ## 6. A "],["data-manipulation.html", "6 Data manipulation 6.1 Setup and Data Loading 6.2 Selecting Columns 6.3 Filtering Rows 6.4 Summarising Data 6.5 Grouping and Group-wise Operations 6.6 Adding Totals 6.7 Creating and Transforming Variables 6.8 Pivoting Data (Reshaping) 6.9 Joining Datasets 6.10 Practical Examples and Patterns 6.11 Tips and Best Practices 6.12 Others 6.13 Quiz: Data Manipulation", " 6 Data manipulation This chapter will focus on the fundamentals of data manipulation. You can identify what the key functions do from the dplyr cheat cheat: As the sheet states, the best way to manipulate data is if your data is tidy (wide) - i.e. each variable is in its own column, and each observation is in its own row. Occasionally you will need long data, such as to build graphs. This sheet demonstrates common data manipulation techniques using the dplyr package in R. Examples use generic placeholder data that can be adapted to your specific datasets. 6.1 Setup and Data Loading First, we’ll load the required packages and read in our data. The dplyr package is part of the tidyverse and provides powerful data manipulation functions. # Load required packages library(dplyr) library(readr) library(tidyr) library(janitor) library(stringr) Next, we’ll read in our main dataset and any supplementary lookup data. This example shows how to handle common data cleaning tasks during the import process. # Read in your main dataset main_data &lt;- read.csv(&quot;path/to/your/main_data.csv&quot;, skip = 0, check.names = FALSE) # Read in supplementary lookup data lookup_data &lt;- read.csv(&quot;path/to/your/lookup_data.csv&quot;) Often, you’ll need to perform basic cleaning and joining operations immediately after loading your data. This code demonstrates how to convert character columns to numeric, join datasets, and filter out unwanted rows. # Basic data cleaning and joining clean_data &lt;- main_data %&gt;% mutate_at(vars(numeric_columns), readr::parse_number) %&gt;% # Convert character columns to numeric left_join(lookup_data %&gt;% select(id_column, category_column), by = &quot;id_column&quot;) %&gt;% filter(entity_column != &quot;Total&quot;) # Remove summary rows 6.2 Selecting Columns The select() function is your primary tool for choosing which columns to keep in your dataset. It’s much more powerful than simple column indexing and provides several flexible approaches. 6.2.1 Basic Column Selection The most straightforward approach is to select columns by name. This is the most reliable method since column names are less likely to change than positions. # Select specific columns by name subset_data &lt;- clean_data %&gt;% select(id_column, name_column) # Using a predefined vector for column names desired_columns &lt;- c(&quot;id_column&quot;, &quot;name_column&quot;, &quot;value_column&quot;) subset_data2 &lt;- clean_data %&gt;% select(all_of(desired_columns)) 6.2.2 Excluding Columns Sometimes it’s easier to specify what you don’t want rather than what you do want, especially when you have many columns. # Select all columns except specific ones no_id_data &lt;- clean_data %&gt;% select(-id_column) # Exclude multiple columns no_admin_data &lt;- clean_data %&gt;% select(-c(id_column, created_date, updated_date)) 6.2.3 Advanced Selection Techniques You can select columns by position (though this should be used cautiously), by data type, or by pattern matching. # Select columns by position (use cautiously) first_columns &lt;- clean_data %&gt;% select(1:5) # Select columns by data type numeric_columns &lt;- clean_data %&gt;% select(where(is.numeric)) # Select columns by pattern value_columns &lt;- clean_data %&gt;% select(starts_with(&quot;value_&quot;)) # Select and rename columns simultaneously renamed_data &lt;- clean_data %&gt;% select(identifier = id_column, entity = name_column, category = category_column) 6.3 Filtering Rows The filter() function allows you to subset your data based on logical conditions. This is essential for focusing your analysis on specific subsets of your data. 6.3.1 Setting Up Custom Operators Before diving into filtering examples, it’s useful to define some custom operators that make filtering more intuitive. # Define custom operators `%notin%` &lt;- Negate(`%in%`) 6.3.2 Basic Filtering Operations These examples cover the most common filtering scenarios you’ll encounter in data analysis. # Exact match filtering filtered_data &lt;- clean_data %&gt;% filter(id_column == 12345) # Text matching filtered_data2 &lt;- clean_data %&gt;% filter(name_column == &quot;Specific Entity&quot;) # Multiple value matching filtered_data3 &lt;- clean_data %&gt;% filter(name_column %in% c(&quot;Entity A&quot;, &quot;Entity B&quot;, &quot;Entity C&quot;)) # Pattern matching with regular expressions filtered_data4 &lt;- clean_data %&gt;% filter(grepl(&#39;keyword&#39;, name_column)) # Contains &#39;keyword&#39; # Negative pattern matching filtered_data5 &lt;- clean_data %&gt;% filter(!grepl(&#39;keyword&#39;, name_column)) # Does NOT contain &#39;keyword&#39; 6.3.3 Logical Operators in Filtering You can combine multiple conditions using logical operators to create more complex filters. # OR condition - either condition can be true filtered_data6 &lt;- clean_data %&gt;% filter(name_column == &quot;Entity A&quot; | name_column == &quot;Entity B&quot;) # AND condition - both conditions must be true filtered_data7 &lt;- clean_data %&gt;% filter(grepl(&#39;keyword1&#39;, name_column) &amp; grepl(&#39;keyword2&#39;, name_column)) # Handle missing values filtered_data8 &lt;- clean_data %&gt;% filter(!is.na(category_column)) # Multiple conditions in one filter (implicit AND) filtered_data9 &lt;- clean_data %&gt;% filter(value_column1 == 0, value_column2 &gt; 100, !is.na(category_column)) 6.3.4 Advanced Filtering with across() The across() function allows you to apply the same filtering logic to multiple columns simultaneously. # Filter rows where specified columns contain specific patterns filtered_advanced &lt;- clean_data %&gt;% filter(across(c(column1, column2), ~ str_detect(., pattern = &quot;pattern&quot;))) # Filter rows with no letters in numeric columns filtered_numeric &lt;- clean_data %&gt;% filter(across(c(numeric_col1, numeric_col2), ~ !str_detect(., pattern = &quot;[A-Z]&quot;))) # Filter rows where values are above threshold filtered_threshold &lt;- clean_data %&gt;% filter_at(vars(value_col1, value_col2), all_vars(. &gt; 100)) # Filter out rows with any missing values complete_cases &lt;- clean_data %&gt;% filter_at(vars(everything()), all_vars(!is.na(.))) 6.4 Summarising Data The summarise() function creates summary statistics from your data. It’s particularly powerful when combined with grouping operations. 6.4.1 Basic Summarisation Here’s how to create summary statistics for your entire dataset: # Basic summary of entire dataset total_summary &lt;- clean_data %&gt;% summarise( total_count = n(), total_value = sum(value_column, na.rm = TRUE), average_value = mean(value_column, na.rm = TRUE), max_value = max(value_column, na.rm = TRUE), min_value = min(value_column, na.rm = TRUE), std_dev = sd(value_column, na.rm = TRUE) ) # View the results print(total_summary) 6.4.2 Summarising Multiple Columns When you need to apply the same summary functions to multiple columns, use across() to avoid repetitive code: # Summarise multiple columns at once multi_summary &lt;- clean_data %&gt;% summarise(across(c(value_col1, value_col2), list(sum = ~ sum(.x, na.rm = TRUE), mean = ~ mean(.x, na.rm = TRUE), count = ~ sum(!is.na(.x))), .names = &quot;{.col}_{.fn}&quot;)) # This creates columns like value_col1_sum, value_col1_mean, value_col1_count, etc. 6.5 Grouping and Group-wise Operations Grouping is one of the most powerful features of dplyr. It allows you to perform operations on subsets of your data defined by the values in one or more columns. 6.5.1 Single Variable Grouping The most common use case is grouping by a single categorical variable: # Group by a single variable grouped_summary &lt;- clean_data %&gt;% group_by(category_column) %&gt;% summarise( count = n(), total_value = sum(value_column, na.rm = TRUE), average_value = mean(value_column, na.rm = TRUE), median_value = median(value_column, na.rm = TRUE), .groups = &quot;drop&quot; # This removes the grouping after summarising ) # View the results print(grouped_summary) 6.5.2 Multiple Variable Grouping You can group by multiple variables to create more detailed breakdowns: # Create a new categorical variable first analysis_data &lt;- clean_data %&gt;% mutate(type_flag = if_else(grepl(&#39;keyword&#39;, name_column), &quot;Type A&quot;, &quot;Type B&quot;)) # Group by multiple variables multi_grouped &lt;- analysis_data %&gt;% group_by(category_column, type_flag) %&gt;% summarise( count = n(), total_value = sum(value_column, na.rm = TRUE), average_value = mean(value_column, na.rm = TRUE), .groups = &quot;drop&quot; ) # This creates a row for each unique combination of category_column and type_flag 6.5.3 Simple Counting Sometimes you just need to count how many observations fall into each group: # Count occurrences by group count_by_group &lt;- clean_data %&gt;% count(category_column, sort = TRUE) # sort = TRUE orders by count descending # Alternative using group_by and summarise count_by_group2 &lt;- clean_data %&gt;% group_by(category_column) %&gt;% summarise(row_count = n(), .groups = &quot;drop&quot;) 6.6 Adding Totals The janitor package provides convenient functions for adding total rows and columns to your summaries. # Add row totals (adds a &quot;Total&quot; row at the bottom) data_with_totals &lt;- grouped_summary %&gt;% adorn_totals(&quot;row&quot;) # Add column totals (adds a &quot;Total&quot; column on the right) data_with_col_totals &lt;- grouped_summary %&gt;% adorn_totals(&quot;col&quot;) # Add both row and column totals data_with_both_totals &lt;- grouped_summary %&gt;% adorn_totals(c(&quot;row&quot;, &quot;col&quot;)) You can verify that your totals are correct and extract specific values: # Verify totals match your expectations total_check &lt;- data_with_totals$total_value[nrow(data_with_totals)] # Extract specific total value extracted_total &lt;- data_with_totals %&gt;% slice_tail(n = 1) %&gt;% pull(total_value) # Check if totals match between different summaries print(paste(&quot;Total matches:&quot;, total_check == sum(clean_data$value_column, na.rm = TRUE))) 6.7 Creating and Transforming Variables The mutate() function is your primary tool for creating new variables or transforming existing ones. It’s incredibly flexible and supports complex operations. 6.7.1 Basic Variable Creation These examples show the most common ways to create new variables: # Create new variables transformed_data &lt;- clean_data %&gt;% mutate( # Simple arithmetic combined_value = value_col1 + value_col2 + value_col3, # Percentage calculations percentage = (value_column / total_column) * 100, # Simple conditional variable binary_flag = if_else(value_column &gt; 100, &quot;High&quot;, &quot;Low&quot;), # Overwrite existing column (apply a transformation) value_column = value_column * 1.1 # Apply 10% increase ) 6.7.2 Complex Conditional Logic For more complex conditions, use case_when(), which is like a vectorised if-else statement: # Complex conditional variable with multiple outcomes complex_data &lt;- clean_data %&gt;% mutate( category_flag = case_when( grepl(&quot;pattern1&quot;, name_column) ~ &quot;Category 1&quot;, grepl(&quot;pattern2&quot;, name_column) ~ &quot;Category 2&quot;, value_column &gt; 500 ~ &quot;High Value&quot;, value_column &lt; 50 ~ &quot;Low Value&quot;, is.na(value_column) ~ &quot;Missing&quot;, TRUE ~ &quot;Other&quot; # This handles all remaining cases ), # Combining multiple conditions complex_flag = case_when( grepl(&quot;important&quot;, name_column) &amp; value_column &gt; 100 ~ &quot;Important and High&quot;, grepl(&quot;important&quot;, name_column) &amp; value_column &lt;= 100 ~ &quot;Important but Low&quot;, !grepl(&quot;important&quot;, name_column) &amp; value_column &gt; 100 ~ &quot;Not Important but High&quot;, TRUE ~ &quot;Other&quot; ) ) 6.7.3 Transforming Multiple Columns When you need to apply the same transformation to multiple columns, use across() or mutate_at(): # Transform multiple columns simultaneously multi_transformed &lt;- clean_data %&gt;% mutate(across(c(value_col1, value_col2), ~ .x * 1000)) # Convert to thousands # Apply custom function to multiple columns custom_function &lt;- function(x) { (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE) # Standardise } standardised_data &lt;- clean_data %&gt;% mutate(across(starts_with(&quot;value_&quot;), custom_function)) # Transform all numeric columns all_numeric_transformed &lt;- clean_data %&gt;% mutate(across(where(is.numeric), ~ round(.x, 2))) # Round to 2 decimal places 6.7.4 Row-wise Operations Sometimes you need to perform calculations across columns within each row: # Create columns from row-wise operations row_operations &lt;- clean_data %&gt;% mutate( # Sum across multiple columns row_sum = rowSums(select(., starts_with(&quot;value_&quot;)), na.rm = TRUE), # Average across multiple columns row_mean = rowMeans(select(., starts_with(&quot;value_&quot;)), na.rm = TRUE), # Count non-missing values per row non_missing_count = rowSums(!is.na(select(., starts_with(&quot;value_&quot;)))), # Find maximum value per row row_max = do.call(pmax, c(select(., starts_with(&quot;value_&quot;)), na.rm = TRUE)) ) 6.7.5 Handling Missing Values Missing values are common in real data. Here’s how to handle them systematically: # Replace missing values with different strategies clean_nas &lt;- clean_data %&gt;% mutate( # Replace with zero value_col1 = replace_na(value_col1, 0), # Replace with mean value_col2 = replace_na(value_col2, mean(value_col2, na.rm = TRUE)), # Replace all numeric columns with zero across(where(is.numeric), ~replace_na(., 0)), # Replace text columns with &quot;Unknown&quot; across(where(is.character), ~replace_na(., &quot;Unknown&quot;)) ) 6.8 Pivoting Data (Reshaping) Data can be organised in “wide” format (variables spread across columns) or “long” format (variables stacked in rows). The pivot_longer() and pivot_wider() functions help you convert between these formats. 6.8.1 Wide to Long Format Long format is often better for analysis and visualisation: # Convert wide data to long format long_data &lt;- clean_data %&gt;% # First, select only the columns you want to pivot select(id_column, name_column, starts_with(&quot;value_&quot;)) %&gt;% # Then pivot the value columns into long format pivot_longer( cols = starts_with(&quot;value_&quot;), # Columns to pivot names_to = &quot;metric&quot;, # Name for the new column containing old column names values_to = &quot;value&quot;, # Name for the new column containing values names_prefix = &quot;value_&quot; # Remove this prefix from the metric names ) # View the structure head(long_data) 6.8.2 Long to Wide Format Sometimes you need to convert long data back to wide format: # Convert long data back to wide format wide_data &lt;- long_data %&gt;% pivot_wider( names_from = metric, # Column containing the new column names values_from = value, # Column containing the values values_fill = 0, # Fill missing combinations with 0 names_prefix = &quot;value_&quot; # Add this prefix to the new column names ) 6.8.3 Advanced Pivoting You can also pivot multiple columns simultaneously: # Pivot multiple value columns complex_long &lt;- clean_data %&gt;% pivot_longer( cols = c(starts_with(&quot;value_&quot;), starts_with(&quot;count_&quot;)), names_to = c(&quot;metric&quot;, &quot;type&quot;), names_pattern = &quot;(.+)_(.+)&quot;, # Extract parts of column names values_to = &quot;amount&quot; ) 6.9 Joining Datasets Joining datasets is crucial for combining information from multiple sources. The type of join you choose depends on how you want to handle records that don’t have matches. 6.9.1 Basic Join Operations The most common join is a left join, which keeps all records from the left dataset: # Basic left join - keeps all records from main_data joined_data &lt;- main_data %&gt;% left_join(lookup_data, by = &quot;common_column&quot;) # Inner join - keeps only records that exist in both datasets inner_joined &lt;- main_data %&gt;% inner_join(lookup_data, by = &quot;common_column&quot;) # Full join - keeps all records from both datasets full_joined &lt;- main_data %&gt;% full_join(lookup_data, by = &quot;common_column&quot;) 6.9.2 Handling Different Column Names Often, the columns you want to join on have different names in each dataset: # Join when column names don&#39;t match joined_different_names &lt;- main_data %&gt;% left_join(lookup_data, by = c(&quot;main_id&quot; = &quot;lookup_id&quot;)) # You can also rename before joining joined_renamed &lt;- main_data %&gt;% left_join(lookup_data %&gt;% rename(main_id = lookup_id), by = &quot;main_id&quot;) 6.9.3 Multiple Column Joins Sometimes you need to join on multiple columns to create a unique match: # Join on multiple columns multi_column_join &lt;- main_data %&gt;% left_join(lookup_data, by = c(&quot;column1&quot;, &quot;column2&quot;, &quot;column3&quot;)) # Mix of same and different column names mixed_join &lt;- main_data %&gt;% left_join(lookup_data, by = c(&quot;same_name&quot;, &quot;main_col&quot; = &quot;lookup_col&quot;)) 6.9.4 Joining Multiple Datasets When you have several datasets to join, you can use reduce() to join them all at once: # Join multiple datasets with a common structure dataset_list &lt;- list( data1 = data1, data2 = data2, data3 = data3, data4 = data4 ) # Join all datasets on common columns multiple_joined &lt;- dataset_list %&gt;% reduce(left_join, by = c(&#39;id_column&#39;, &#39;name_column&#39;)) 6.10 Practical Examples and Patterns 6.10.1 Complete Data Processing Pipeline Here’s a comprehensive example that combines many of the techniques we’ve covered: # Complete data processing pipeline processed_data &lt;- raw_data %&gt;% # Step 1: Clean and standardise the data mutate_at(vars(starts_with(&quot;numeric_&quot;)), parse_number) %&gt;% filter(!is.na(id_column), !grepl(&quot;test&quot;, name_column, ignore.case = TRUE)) %&gt;% # Step 2: Join supplementary data left_join(lookup_data, by = &quot;id_column&quot;) %&gt;% # Step 3: Create derived variables mutate( # Calculate totals total_score = rowSums(select(., starts_with(&quot;score_&quot;)), na.rm = TRUE), # Create categories performance_category = case_when( total_score &gt;= 80 ~ &quot;High&quot;, total_score &gt;= 60 ~ &quot;Medium&quot;, total_score &gt;= 40 ~ &quot;Low&quot;, TRUE ~ &quot;Very Low&quot; ), # Create flags has_complete_data = !is.na(total_score) &amp; !is.na(category_column), # Calculate percentages score_percentage = (total_score / max(total_score, na.rm = TRUE)) * 100 ) %&gt;% # Step 4: Filter to final analysis sample filter(has_complete_data, total_score &gt; 0) %&gt;% # Step 5: Group and summarise group_by(performance_category, region) %&gt;% summarise( count = n(), avg_score = mean(total_score, na.rm = TRUE), median_score = median(total_score, na.rm = TRUE), std_dev = sd(total_score, na.rm = TRUE), .groups = &quot;drop&quot; ) %&gt;% # Step 6: Add totals and format adorn_totals(&quot;row&quot;) %&gt;% mutate(across(where(is.numeric), ~ round(.x, 2))) 6.10.2 Function-Based Processing For repetitive tasks, create custom functions: # Create a function to standardise dataset processing process_dataset &lt;- function(df, dataset_name) { df %&gt;% # Add source identifier mutate(source = dataset_name) %&gt;% # Standardise column names select(id = id_column, name = name_column, value = value_column, category = category_column, source) %&gt;% # Clean data filter(!is.na(value), value &gt; 0) %&gt;% # Add standardised metrics mutate( value_scaled = scale(value)[,1], value_log = log(value + 1) ) } # Apply function to multiple datasets datasets &lt;- list( africa = africa_data, asia = asia_data, europe = europe_data, americas = americas_data ) # Process all datasets and combine combined_data &lt;- map_dfr(datasets, process_dataset, .id = &quot;region&quot;) 6.11 Tips and Best Practices 6.11.1 Data Validation Always validate your data transformations: # Check data before and after transformations original_rows &lt;- nrow(raw_data) processed_rows &lt;- nrow(processed_data) print(paste(&quot;Original rows:&quot;, original_rows)) print(paste(&quot;Processed rows:&quot;, processed_rows)) print(paste(&quot;Rows lost:&quot;, original_rows - processed_rows)) # Check for unexpected missing values missing_summary &lt;- processed_data %&gt;% summarise(across(everything(), ~ sum(is.na(.)))) print(&quot;Missing values by column:&quot;) print(missing_summary) 6.11.2 Performance Considerations For large datasets, consider these optimisation strategies: # For large datasets, filter early to reduce processing time large_data_processed &lt;- large_dataset %&gt;% filter(important_flag == TRUE) %&gt;% # Filter first mutate(expensive_calculation = complex_function(value_column)) %&gt;% # Then transform group_by(category) %&gt;% summarise(result = mean(expensive_calculation)) # Use data.table for very large datasets library(data.table) setDT(large_dataset) result &lt;- large_dataset[important_flag == TRUE, .(mean_value = mean(value_column)), by = category] 6.11.3 Debugging and Troubleshooting When your code doesn’t work as expected: # Test transformations on small subsets first test_data &lt;- clean_data %&gt;% slice_head(n = 10) # Check intermediate results debug_pipeline &lt;- clean_data %&gt;% mutate(new_variable = some_transformation) %&gt;% {print(paste(&quot;Rows after mutate:&quot;, nrow(.))); .} %&gt;% # Debug print filter(some_condition) %&gt;% {print(paste(&quot;Rows after filter:&quot;, nrow(.))); .} %&gt;% # Debug print group_by(category) %&gt;% summarise(result = mean(new_variable)) In order to make a data frame that’s easy to subset, you might want to define the row names. When defining row names, each one needs to be unique. I.e. you should use wide data, and the row names should be a unique column. For this example, we’ll create our own data frame. However, if you want to see a dataset where a column has already been made into row names, see the mtcars data. A pre-loaded dataset in R. (rundata(\"mtcars)) # Define a 5x3 data frame Test_Data &lt;- as.data.frame(tibble(name = c(&quot;Abdus&quot;, &quot;Sarah&quot;, &quot;Yilan&quot;, &quot;Michael&quot;, &quot;Alex&quot;), office = c(&quot;CH&quot;, &quot;SB&quot;, &quot;PG&quot;, &quot;PG&quot;, &quot;CH&quot;), manager = c(&quot;Sarah&quot;, &quot;Yilan&quot;, &quot;Frank&quot;, &quot;Yilan&quot;, &quot;Michael&quot;))) #It looks like this: # name office manager # name office manager # 1 Abdus CH Sarah # 2 Sarah SB Yilan # 3 Yilan PG Frank # 4 Michael PG Yilan # 5 Alex CH Michael # You&#39;ll see our row names are 1:5, therefore you can extract the first row in the manager column like this: Abdus_Manager1 &lt;- Test_Data[&quot;1&quot;, &quot;manager&quot;] print(Abdus_Manager1) # [1] &quot;Sarah&quot; # NOTE: if the Test_Data was not a data frame (i.e. was just a tibble). You would need to do pull(Test_Data[&quot;1&quot;, &quot;manager&quot;]) OR Test_Data[&quot;1&quot;, &quot;manager&quot;] %&gt;% pull() # We can give the table row names using the column to row names # This wouldn&#39;t work for the `office` column because there are multiple PGs Col_Indexed_Test_Data &lt;- Test_Data %&gt;% column_to_rownames(., var = &quot;name&quot;) # Our data now look like this # office manager # office manager #Abdus CH Sarah #Sarah SB Yilan #Yilan PG Frank #Michael PG Yilan #Alex CH Michael #Now we can pull with specified inputs. Abdus_Manager2 &lt;- Col_Indexed_Test_Data[&quot;Abdus&quot;, &quot;manager&quot;] print(Abdus_Manager2) #[1] &quot;Sarah&quot; An alternative way to extract data is by filtering columns until you end up with a single row, at which point you can use the pull() function to extract the data point in the column you are after. Abdus_Manager3 &lt;- Test_Data %&gt;% filter(name == &quot;Abdus&quot;) %&gt;% pull(manager) Use [[]] to return an element in a list; use for recurssive indexing. See iris[[2]] vs iris[2]. Double square brackets are often necessary to pinpoint elements. 6.12 Others Most data manipulation functions can be found in the dplyr cheat sheet and are fairly intuitive to use. Particularly useful are binding functions: cbind() in BaseR, bind_cols() in dplyr. Also pull() and rename() 6.13 Quiz: Data Manipulation ## **1. Which dplyr function is used to select columns from a data frame?** ## ## A) filter() ## B) select() ## C) mutate() ## D) arrange() ## ## **2. To keep rows where `category_column` is either &#39;A&#39;, &#39;B&#39;, or &#39;C&#39;, which filter condition is most suitable?** ## ## A) filter(category_column | c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;)) ## B) filter(category_column %in% c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;)) ## C) filter(category_column == c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;)) ## D) filter(grepl(&#39;A|B|C&#39;, category_column)) ## ## **3. What is the primary purpose of combining `group_by()` and `summarise()`?** ## ## A) To create new columns based on complex conditions. ## B) To reshape data from wide to long format. ## C) To calculate summary statistics for different groups within the data. ## D) To join two different data frames together. ## ## **4. Which function is best for creating a new column using complex, multi-level conditional logic?** ## ## A) if_else() ## B) select() ## C) case_when() ## D) filter() ## ## **5. To reshape a &#39;wide&#39; data frame with many columns (e.g., `value_2020`, `value_2021`) into a &#39;long&#39; format, which function should you use?** ## ## A) pivot_wider() ## B) gather() ## C) pivot_longer() ## D) spread() ## ## **6. In a `left_join(x, y, by = &#39;id&#39;)`, what happens to the rows in `x` that do not have a matching `id` in `y`?** ## ## A) They are removed from the final result. ## B) They are kept, and the new columns from y are filled with NA. ## C) The join operation produces an error. ## D) They are kept, and the new columns from y are filled with 0. ## ## **7. Which function from the `janitor` package is used to add a &#39;Total&#39; row to a summary table?** ## ## A) add_totals() ## B) adorn_totals() ## C) make_totals() ## D) summarise_totals() ## ## --- ## ## **Answers:** ## ## 1. B ## 2. B ## 3. C ## 4. C ## 5. C ## 6. B ## 7. B "],["user-defined-functions.html", "7 User-defined Functions 7.1 Overview 7.2 Basic examples 7.3 Returning objects 7.4 Passing objects 7.5 Setting default inputs 7.6 Using Loops 7.7 Random snippets 7.8 Quiz: User defined functions quiz", " 7 User-defined Functions The advanced technicalities of User-Defined Functions (UDFs) are, in most instances, outside the scope of this book. If you would like to read more about the specifics covered here, some good resources are: Quasiquotation Tidy evaluation (data masking and tidy selection) Assignment by reference 7.1 Overview This chapter is a quick introduction to UDFs. It also aims to give you some of the tools to overcome specific issues you are likely to encounter as you start to use them more frequently. UDFs give you the power to automate and generalise code. They allow analysts to retain control over function inputs, whilst also minimising the risk of error. User-defined functions are easier to QA and are more readable than large chunks of repeated code. In general, a good rule is to write a function if you are going to be using a chunk of code more than twice (you can also write a function retrospectively if you notice you’ve copied a chunk of code several times). As with everything in this book, there is no single way to go about writing functions. Do what works for you, and what helps you to achieve the goal you set out. In order to write a function you need: a name for it; input parameters; an operation for the function to perform; and an output or outputs. 7.2 Basic examples In the most basic sense, a function can be used to perform the operation fed to it. In this way you could: firstly, copy and paste any working code into a UD function; save the function; then run the function; and finally observe that the code has been executed. # Using the existing print() function: print(&quot;Hi my name is&quot;) # will print the string &quot;Hi my name is&quot; [1] &quot;Hi my name is&quot; # Creating our own function # This assigns a function to the name Print_Function # The function will be performed on all elements in the curly brackets, denoted by the &quot;.&quot; in the function inputs. In actual fact you could put anything in here; it won&#39;t be evaluated. # The curly brackets open and close the function. The code between is the operation. Print_Function &lt;- function(.){ # Define and name the function print(&quot;Hi my name is&quot;) #give it an operation } #close it Print_Function() # run the function (with no specified input parameters) [1] &quot;Hi my name is&quot; 7.3 Returning objects Objects created within a function will not be stored in the global environment, unless R is told specifically to do this. This is very useful if you want to create lots of objects temporarily. It does, however, mean you need to know how to extract the relevant objects from your data frame. The usual &lt;- (assignment) operator will create an object to be used within the function, but this will not be exported to the global environment. The &lt;&lt;- operator will assign the object created to the global environment regardless of where it appears in the function, or whether your function is run to designate a new object. See below for more clarity. Assigmment function 1 creates 3 variables: a, b and d. I use “d” because c is the combine function itself. We then run the function, which creates the variables but doesn’t assign them to any objects in the global environment. # create a function, which, within it creates 3 objects: a,b,d Assignment_Func_1 &lt;- function(.){ a &lt;- 1 b &lt;- 2 d &lt;- 3 } # running the function will do nothing Assignment_Func_1() Assingment function 2 is identical to #1, except that we designate the function to the variable x. This assigns x the value 3 because d was the final object created in the function. Assignment_Func_2 &lt;- function(.){ a &lt;- 1 b &lt;- 2 d &lt;- 3 } # running the function and assigning it to an object, x x &lt;- Assignment_Func_2() # test what has happened print(x) [1] 3 To demonstrate that the objects a and b are created within the function, see the iteration 2.1 below. The function still outputs the value of d because it is the last thing created, but we use the prior objects to generate d. Assignment_Func_2b &lt;- function(.){ a &lt;- 1 b &lt;- 2 d &lt;- a + b } x &lt;- Assignment_Func_2b() print(x) [1] 3 If we wanted to specify which object to assign as our output we could use the return() function. Assignment function 3 finishes by returning a, therefore, when we assign the output of the function to our variable, x, it is assigned the value 1 (equivalent to a). Assignment_Func_3 &lt;- function(.){ a &lt;- 1 b &lt;- 2 d &lt;- 3 return(a) } x &lt;- Assignment_Func_3() print(x) [1] 1 We can also assign objects created within the function using the &lt;&lt;- operator. If you were to run print(a), print(b) or print(d) in your console at any point so far you would have seen this error: Error in print(b) : object 'b' not found. We can, however, create these objects. Assignment function 4 does this. It creates 2 objects, b and d, in addition to assigning x the value of 1 (because we have returned (a)) Assignment_Func_4 &lt;- function(.){ a &lt;- 1 b &lt;&lt;- 2 d &lt;&lt;- 3 return(a) } x &lt;- Assignment_Func_4() print(b) [1] 2 print(x) [1] 1 7.4 Passing objects You can pass objects through functions. This helps to generalise ta function’s inputs. Inputs might be objects, vectors, strings, numbers, columns etc. Print_Object &lt;- function(Input_String){ print(Input_String) } Print_Object(Input_String = &quot;Hello, is it me you&#39;re looking for&quot;) [1] &quot;Hello, is it me you&#39;re looking for&quot; When passing more complicated inputs, you might need to know about other operators. The main things to be aware of are {{}}, := and !!. To do this, we will reload the iris data and play about with generalising our inputs. You might also need to be careful about how an input is read in: ether as as string (wrapped in speech marks) or an object. library(dplyr) #Load dplyr package data(&quot;iris&quot;) #Load the iris data 7.4.1 Creating the function #Create an average sepal length table Summary_Function &lt;- function(.){ Summary_Table &lt;- iris %&gt;% group_by(Species) %&gt;% summarise(Average_Sepal_Length = mean(Sepal.Length)) } Av_Sepal_Length_Table &lt;- Summary_Function() print(Av_Sepal_Length_Table) # # A tibble: 3 x 2 # Species Average_Sepal_Length # 1 setosa 5.01 # 2 versicolor 5.94 # 3 virginica 6.59 7.4.2 Passing data #Create an average sepal length table Summary_Function &lt;- function(DATA_FRAME){ Summary_Table &lt;- DATA_FRAME %&gt;% group_by(Species) %&gt;% summarise(Average_Sepal_Length = mean(Sepal.Length)) } Av_Sepal_Length_Table &lt;- Summary_Function(DATA_FRAME = iris) print(Av_Sepal_Length_Table) # # A tibble: 3 x 2 # Species Average_Sepal_Length # 1 setosa 5.01 # 2 versicolor 5.94 # 3 virginica 6.59 Now, as we try to involve more complex arguments, we need to tell R more about the objects we are passing through it. Different functions work in different ways. The group_by() and summarise() functions look for the variables as quoted arguments. In order to tell R that the object being passed is in fact a variable name, we need to use {{}} (curly-curly). Also, note that we’ve had to use := (colon equals) instead of =. This will also be true for mutate() functions when you mutate columns by having passed the column name through the function. It allows you to perform assignments by reference. #Create an average sepal length table Summary_Function &lt;- function(DATA_FRAME, GROUP_BY_COL, SUMMARY_COL){ Summary_Table &lt;- DATA_FRAME %&gt;% group_by({{GROUP_BY_COL}}) %&gt;% summarise({{SUMMARY_COL}} := mean(Sepal.Length)) } Av_Sepal_Length_Table &lt;- Summary_Function(DATA_FRAME = iris, GROUP_BY_COL = Species, SUMMARY_COL = Average_Sepal_Length) print(Av_Sepal_Length_Table) # # A tibble: 3 x 2 # Species Average_Sepal_Length # 1 setosa 5.01 # 2 versicolor 5.94 # 3 virginica 6.59 Finally, it might be that you need your inputs to change between quoted and unquoted arguments. In the example below, given the nature of the vector, these elements need to be in quotations. But when we call them in our dplyr chain, we want R to recognise them as objects. We use as.name, a base R fuction that takes a string (or a variable containing a string) and returns the content of the string as a variable name. The !! (bang-bang) tells the summarise function to not take the value as it is, but to substitute the real value. #Create an average sepal length table Summary_Function &lt;- function(Col_Vector, i){ #depending on the value of i, this will extract the element in position i of the Col_Vector. It assigns the string to an element, Col_Averaging Col_Averaging &lt;- Col_Vector[i] Summary_Table &lt;- iris %&gt;% group_by(Species) %&gt;% summarise(!!as.name(paste0(&quot;Average_&quot;, Col_Averaging)) := mean(!!as.name(Col_Averaging))) #the paste0 is to generalise the column title as a concatenaetion of Average and the Column we select. } Av_Table &lt;- Summary_Function(Col_Vector = c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, &quot;Petal.Length&quot;, &quot;Petal.Width&quot;), i = 2) print(Av_Table) # A tibble: 3 x 2 # Species Average_Sepal.Width # 1 setosa 3.43 # 2 versicolor 2.77 # 3 virginica 2.97 7.5 Setting default inputs You can tell a function that if an input is not specified otherwise, to autofill that argument with something pre-determined. My_Print_Function &lt;- function(Input_String = &quot;The assigned default input&quot;){ print(Input_String) } My_Print_Function() [1] &quot;The assigned default input&quot; My_Print_Function(&quot;Print this instead&quot;) [1] &quot;print this instead&quot; Another key for setting defaults is ensuring that your function can work both on its own and within dplyr pipes. You can often get away with setting one of the function arguments to be “data_frame”. If you are in a dplyr pipe, you will not need to manually specify this argument because R will just assign the first element you’re working with to be a data frame. If you want to be able to call the data_frame object and interact with it, then you should tell R this. Setting the argument: data_frame = .data will allow you to do this. In this way, if you are working outside a dplyr pipe, you can reassign the object such that data_frame = insert_name_of_your_data . Alternatively, if you are in a pipe, you will be able to use the data_frame object within the function. 7.6 Using Loops Loops are often more computationally intensive than functions from the apply() family. See this guidance for usage details. it can be harder to get your head around. Loops increase the power (and running time) of functions . They allow you to specify the array sets on which to apply functions. The two most used loop functions are for() and while(). Generally, for() loops are easier to use, unless the condition changes as the function evolves. In the most basic sense, these formulae do the same thing: # 1. i &lt;- 1 while(i &lt; 4){ print(i) i &lt;- i + 1 } #2. for(i in 1:3){ print(i) } While loops are useful when we don’t know exactly when to terminate the loop. They do, however, require us to define an evolving condition. More common is to know the set around which we need to loop. This will usually be a number or vector (remember vectors can vary in length). E.g., you could run a loop around i in 1:length(vector) You can apply vectors over multiple objects using the apply() family of functions: tapply(), sapply(), lapply(). You can also achieve this with loops The function get() can be used to turn a text string into an object (similar to !! and {{}}). It is more flexible. # deinfe a vector of the data frame names df_vector &lt;- c(“df1”, “df2”, “df3) # loop around the vector you&#39;ve defined for(i in df_vector){ # assign an object, df, to be the object i df &lt;- get(i) %&gt;% # transform object mutate(sdaiusfd) # reassign the object in the global environment with the same name as i to be the df we&#39;ve just manipulated # you could change the name of i with paste0() if you wanted assign(i, df) } # remove elements used in loop rm(i, df) 7.7 Random snippets Assign a variable out of a loop so that the outputs have different names assign(paste0(&quot;output_name_start_&quot;, year_suffix), df, inherits = TRUE) Evaluate a name as a text string with deparse(substitute(name)) Create a blank tibble with names from a vecotr, cols_vector. You can use this to bind rows to the bottom of. blank_df &lt;- cols_vector %&gt;% purrr::map_dfc(~tibble::tibble(!!.x := logical())) 7.8 Quiz: User defined functions quiz ## **1. If a user-defined function does not have an explicit `return()` statement, what does it output?** ## ## A) The first object created in the function. ## B) A NULL value. ## C) The value of the last expression evaluated in the function. ## D) It produces an error. ## ## **2. Which operator, when used inside a function, assigns a variable to the global environment, making it accessible outside the function?** ## ## A) &lt;- ## B) = ## C) -&gt; ## D) &lt;&lt;- ## ## **3. When writing a function that uses `dplyr`, which special operator is used to embrace an unquoted column name passed as an argument?** ## ## A) !! ## B) [[]] ## C) {{}} ## D) . ## ## **4. Inside a `dplyr` verb like `mutate()` or `summarise()`, which operator must be used on the left side of an assignment when the new column&#39;s name is provided by a function argument?** ## ## A) = ## B) := ## C) &lt;- ## D) ~ ## ## **5. How do you provide a default value for an argument in a function definition?** ## ## A) `my_func &lt;- function(arg: &#39;default&#39;)` ## B) `my_func &lt;- function(arg is &#39;default&#39;)` ## C) `my_func &lt;- function(arg = &#39;default&#39;)` ## D) `my_func &lt;- function(default(arg, &#39;default&#39;))` ## ## **6. What is the primary difference between a `for` loop and a `while` loop?** ## ## A) `for` loops are faster than `while` loops. ## B) Only `for` loops can iterate over vectors. ## C) A `for` loop iterates over a fixed sequence, while a `while` loop runs as long as a condition is true. ## D) A `while` loop requires a start and end number, but a `for` loop does not. ## ## **7. Inside a loop, which base R function can retrieve an object from the environment using a variable that contains its name as a string?** ## ## A) assign() ## B) get() ## C) object() ## D) find() "],["graphs.html", "8 Graphs 8.1 Graphical resources 8.2 Tips 8.3 Arranging 8.4 Basic interactivity", " 8 Graphs 8.1 Graphical resources There are many resources dedicated to data visualisation, which are infinitely more comprehensive than this book could be. Some of the most useful links I have found are contained below. If you are looking to make maps, see the numerous links in the Spatial Chapter R Graph Gallery Plotly - advanced charts including statistical charts, maps, interactive features etc. Colour palettes including showing colour blind tests of palettes. Fonts are also downloadable. Blog on choosing colours Blog landing page Guide to beautiful plotting in R From data to Viz contains to dos and don’t about data visualisation. Also helps with chart selection. 8.2 Tips The order in which you add elements to a ggplot graph matters. You can overwrite your previous code. Fill and colour - both arguments within ggplot::aes() - control different things: the fill and outline, respectively. To resize test, rel() can achieve this. You can also define the order of a facet wrap of multiple graphs. theme(strip.text.x = element_text(face=&quot;bold&quot;, size =16), text = element_text(size = rel(4)), legend.text = element_text(size = rel(4)), plot.caption = element_text(size = rel(3))) + facet_wrap(~factor(Ofs_Tariff_1920, levels = Tariff_Order1)) Add line to a plot using geom_vline() or geom_hline(aes(yintercept = object_or_value), alpha = 0.5, linetype = \"dashed\") + 8.3 Arranging Arranging your data is essential for displaying data well. This might be the order of a categorical axis or a discrete colour scale. In order to do this, wrap the aes argument: ggplot(aes(x = factor(x_column_name, levels = x_axis_order), y = y_col_name, color = factor(Tariff, levels = Tariff_Order 8.4 Basic interactivity if you include a text argument within the ggplot::aes() function, you can create interactive charts. Use ‘’, the .html code for returning to a new line, to create other lines. You can also use functions to control formatting such as bolding. When rendering in an output, use ggplotly(graph_object_name, tooltip = \"text\"). "],["Spatial_Analysis.html", "9 Spatial Analysis", " 9 Spatial Analysis Below are links to resources for spatial analysis in R Geocomputation with R Intro to GIS and Spatial Analysis Spatial Data Science with R and Terra Spatial Data Science With Applications in R Mapping and Spatial Regressions Spatial Modelling for Data Scientists Geospatial Data Science in R Tidy Geospatial Networks in R R as GIS for Economists Spatial Microsimulation with R Code and Context for Data Science in Government spNetwork: an R package to perform spatial analysis on networks "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
