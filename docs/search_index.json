[["index.html", "HE R training Chapter 1 Introduction", " HE R training Tom Harris 2022-07-07 Chapter 1 Introduction This book was produced by Tom Harris for the Higher Education Economics team. Its contents are intended to help both new and experienced R users by covering key features of the R programming language and R studio. The applications try to focus, where possible, on data and outputs that are common in higher education analysis. Users of this resource should add and replace sections where appropriate. If you are new to the team, you should ask the owner of this resource for an onboarding session: a workshop where they go through how to open and download R, the book and the contents of the technical resources folder, in order to answer any questions you have. This session should give you the building blocks to use the book in your work and to interact with other resources in the folder. For any questions, suggestions or if you would like to make a contribution, please contact: Tom Harris thomas.harris@education.gov.uk HEEAT Internal resources There are R resources contained within the HEEAT Technical Resources EDAP area. These are being constantly updated. These include: The Core Learning RBookdown (which you are currently reading) A miscellaneous R code Notebook (where people can dump odd bits of code that don’t fit anywhere) Example projects and scripts Scripts of generic user-defined functions, written or used by the team Scripts containing “useful code” - code that produces things such as dashboards and RShiny apps. These scripts generally stand alone, and might link to data sources. External resources (this is not an exhaustive list and click the text to use hyperlinks) DfE’s Analytics Academy Hadley Wickham’s R for Data science book DfT’s R cookbook ESFA’s R cookbook R cheat sheets Stack Overflow (for questions tagged ‘R’) Swirl learn R in R Search Engines YouTube Datacamp R Graph Gallery A starting point for ALL your graphical needs. Notes These chapters assume some minimal prior understanding of R i.e. what it is; how to download R studio/set it up; and what some of its capabilities are. If you have never used R before, you might want to engage in some other materials first. See DfE’s Analytics Academy, particularly novice level 1 - 4, or swirl. Google, Youtube or colleagues who use R are also good starting points. This book is an collation of RMarkdown scripts which correspond to .R scripts in the accompanying project folder. Those scripts run ordinally through chapters in this book. You can open up the scripts, which contain the code to load data files and manipulate them in the ways that are shown in this book. There might be some slight discrepancies between the book and those scripts, though these should not change anything fundamentally. All the code should run if the working directory is set accordingly. As with any coding language, there are many different ways to achieve the goals that we cover in this book. How you go about tackling any problem a personal choice. The code I present here aims to provide a basis from which you can iterate and probably improve. If you know of better or different methods to those you read, please do share them so that others can benefit from your knowledge. "],["Basics.html", "Chapter 2 Basics of R 2.1 Files 2.2 R Projects 2.3 R Studio’s Panes 2.4 Packages 2.5 Data types 2.6 Data structures", " Chapter 2 Basics of R To make sure you have the most up-to-date version of R, run this code: if (!require(installr)) { install.packages(&quot;installr&quot;) require(installr) } #load / install+load installr # using the package: updateR() 2.1 Files This chapter focuses on working with R scripts. File type: &lt;File_Name.R&gt;. Of course, there are numerous different types of files and projects you can work with in R, including markdowns, bookdowns, presentations and shiny apps. Different file types have their own suffixes. R files end in .R; RMarkdown files end in .Rmd; text files end in .txt etc. As with any work, how you save and document your work is a choice. Depending on the objective, different approaches might be taken. For basic data analysis you have two main options, both of which are valid. You can just open an R script, save it in a file location and work from there. You will need to tell the R script where it is saved by setting your working directory. This is fine for ad hoc bits of work, but for bigger things, you should use R projects 2.2 R Projects Projects act as a way to group your scripts and therefore separate out your work strands. When you open a project, the files pane will automatically open up as where the project is saved. This then allows you to see all your files. To create a project, click file + new project. To create a script within this project, click file + new file + R script. Projects also enable version control through git and devops. In order to learn about these, see the stats production guidance on git, the ESFA guidance on git and the analytics academy videos on git. More on this later. Projects sit in a specified file location, and enable a user to work across multiple files and locations within(/below/behind) where that project is saved. When working in R, the project you have open can be seen in the top right of the pane. In order to pull in data and work interactively with other scripts, you need to tell R which working directory these files are in, so it knows where to look. Once setting your working directory you can work across other files as stated above. If you are unsure of what this means, run (in either the console or a script) this code: getwd() #this code will tell you the file path you are currently working in If your working directory is not where the project is saved, set it to that path. For example: setwd(&quot;//vmt1pr-dhfs01/Working/HE-EAT-WKG-FS&quot;) You can tab across after the forward slashes to find a file location or, alternatively, paste a file location from your file explorer. Important to note is that R reads forward slashes and backslashes differently to the file explorer. A file path in R generally requires forward slashes (or double backslashes). To normalize a file path that you’ve copied directly from an explorer window, you can use the function normalizePath() or readClipboard() with the copied file path. There are two ways to define paths to a file or directory: Relative paths which find a location from an existing location, rather than the root of the file system. Relative paths cannot, therefore, span different drives. Absolute paths which are defined by including an entire path from the root directory Having set your file location, you can then navigate and source files from anywhere within that file location. Relative paths can be coded using /, ~ and ... For more information see this web page The most common usage of relative pathing will be using .. to navigate upwards and / to navigate downwards. Say your working directory is: //vmt1pr-dhfs01/Working/HE-EAT-WKG-FS/Graduate Outcomes, but you wanted to access a file in the Working folder, 2 subfolders above the Graduate Outcomes folder, you could navigate here with 2x ..s: source(&quot;../../example_folder_name&quot;) Another way to do this would be to set your working directory to that folder, access the file, then reassign the working directory to where it was before. 2.3 R Studio’s Panes The R Studio window splits up into four quadrants, which can be dragged and adjusted depending on what you wish to focus on. Each pane has different functions, the basics of which are covered below. Left hand side: Where you run and store code. Code can be run by highlighting the code in a script (top left) and pressing ctrl + enter, OR by writing it in the console (bottom left) and pressing enter. The ‘Run’ button at the top right of the source pane will also execute code. Usage: code that you want a record of, and might want to re-run should be written and run in scripts. Code that you do not need to save can be written in the console. Things like getwd() or data exploration functions are, therefore, usually written in the console. Right hand side Your files will show up in the files pane in the bottom right. Also this for viewing plots (all plots are stored behind each other in the plots tab, if you want to navigate between old and new plots you’ve produced). The help bar is also contained in the bottom right pane. If you are ever unsure about the documentation or application of a function, package or command you can run: `?`(function_name()) the helper will then appear. The environment (top right) is where all the objects, values and functions you create will sit. Also, if you’ve connected to a server, this connection will appear in the connections tab. Your history is stored in the history tab. You want to clear the environment semi-regularly, so that you are not interacting with or using objects that do not exist if you re-run your code. They might have been removed or created in a way that does not create the proper object if you were to re-run your code from start to end. Set your global options to never save ,RData on exit. Do this by clicking tools + global options + general. To see all the items in the environment use ls() To remove an item use # remove 2 objects rm(object_name1, object_name2) # remove all objects rm(list = setdiff(ls(), c(&quot;hep_go_final&quot;))) 2.4 Packages R uses packages and functions to enable you to work efficiently. BaseR is pre-installed. It contains basic functions to assign objects, create ‘if’ statements, add two numbers together, create lists etc. Additionally, because R is an open source programme, developers have built other packages which you can install and load into R. These packages contains functions and functionality which can make coding easier and more efficient. Any uninstalled package needs to be installed first: install.packages(“package_name”) Once a package is installed, its functionality can be used by loading it into your project library(installed_package_name) To load my packages at the start of a project, I link to a script with this code in. The pacman::p_load function loads packages if they’re installed already, installs them then loads them if not. The set of packages are the core ones I use in lots of work I do. You might want to add or take others out. if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) #this will load the pacman package pacman::p_load(dplyr, #the :: specifies to use the p_load function from the pacman package. Some functions are named identically in more than one package; this ensures you use the correct one. data.table, stringr, stringi, tidyverse, janitor, scales, rmarkdown, plotly, ggplot2, stats, openxlsx) #add any packages to this list If any packages cannot be installed, you might be using an outdated version of R. To update it: # Run this to install &#39;updateR&#39; if (!require(installr)) { install.packages(&quot;installr&quot;) require(installr) } #load / install+load installr # use the package to update your R: updateR() 2.5 Data types R has various data formats and types. Working with R, it is important to appreciate that there are nuances between data types. They are useful for different things, and get called in different ways. R has 6 basic data types. character: “a”, “swc” numeric: 2, 15.5 integer: 2L (the L tells R to store this as an integer) logical: TRUE, FALSE complex: 1+4i (complex numbers with real and imaginary parts) raw Sometimes you will need to transform the data type. For example, if numbers are stored as characters. This will prohibit mathematical functionality. To convert between data types, use as.numeric, as.logical and others as functions or as arguments within other functions. The most basic example to change a column’s data type mutate(example_column = as.numeric(example_column)). Be careful when converting text to numbers, as.numeric will return “NA” if you try to convert “6,377” to 6377, because of the comma. To get around this, consider string manipulation functions from the stringi or stringr packages, or readr::parse_number. For more examples of changing data structures see the data manipulation chapter or the (more advanced) user-defined functions chapter. 2.6 Data structures R has many data structures. These include: data frame vectors (atomic vectors are vectors with one type of data) factors matrix list 2.6.1 Data Frames A data frame is an array of rectangular data (which makes it easy to manipulate). Any table you load in correctly from excel will be stored as a data frame. For the purposes of exploration below, we will load in the iris dataset. This is pre-loaded to R. We can explore the data using functions in BaseR data(&quot;iris&quot;) # it is a data frame with 5 elements and 150 variables class(iris) # tells us it is a data frame [1] &quot;data.frame&quot; # How many rows does the data have nrow(iris) [1] 150 # How many elements are in the data frame length(iris) [1] 5 names(iris) # What are the column names [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; &quot;Species&quot; # What are the unique variables in the species column. These are stored as a factor with 3 levels unique(iris$Species) [1] setosa versicolor virginica Levels: setosa versicolor virginica # What is the structure of the data. What are the variable types? You can also view the data set str(iris) [1] &#39;data.frame&#39;: 150 obs. of 5 variables: $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ............. $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... # Open the data frame in a pane. You can hover over the column index, column title and see the data structure and range View(iris) 2.6.2 Vectors A vector is a sequence of data elements. Vectors will contains elements of the same type or will convert the elements implicitly. In a vector, the order matters. If you think mathematically, R reads a vector in order. This is one way a vector is distinguished from a list We can use the assign syntax &lt;- c() to assign vectors x &lt;- c(1, 2, 3) #R will create an vector, x, with 3 numeric elements x1 &lt;- c(1, 2, 3, &quot;4&quot;) #R will read all elements as characters because we specified that 4 is a character y &lt;- c(10, 100, 1000) z &lt;- x * y # vectors can be multiplied vectors can also be character strings GO_Team &lt;- c(&quot;Gabe&quot;, &quot;Hindowa&quot;, &quot;Tom&quot;) GO_Team[3] #this it the element in position 3 [1] &quot;Tom&quot; 2.6.3 Factors A factor is essentially a vector of n integer values with a corresponding set of character values. The only input argument you need to specify is a vector of values from any atomic (same data) type, and the factor function will return a vector of factor values. This relates to the concept of levels, where the level of a factor is basically the number of distinct elements, in reverse order to how they are written. You can specify the levels if you wish to change the order. GO_Employee_Of_The_Week &lt;- factor(c(&quot;Tom&quot;, &quot;Tom&quot;, &quot;Tom&quot;, &quot;Tom&quot;, &quot;Hindowa&quot;), ) #creates a factor in the global environment. You can specify the order of the levels. If not specified, R will do this automatically (in reverse to the order they appear) print(GO_Employee_Of_The_Week) # [1] Tom Tom Tom Tom Hindowa Levels: Hindowa Tom # You could specify the levels with a levels = argument. E.g. levels = # c(&#39;Hindowa&#39;, &#39;Tom&#39;) levels(GO_Employee_Of_The_Week) # the levels are the order in which the elements appear GO_Employee_Of_The_Week[5] #this returns the element in position 5 of the factor Factor levels are important when you need to specify the order of something e.g. to arrange graphs by High , Medium, Low, Specialist, this uses a tariff vector x &lt;- c(\"High\", \"Medium\", \"Low\", \"Specialist\") as the levels for turning the tariff column into a factor. 2.6.4 Matrices Matrices are used in regression analysis and other more complex data exercises, but not much in the standard outputs we produce. A matrix is a collection of elements of the same data type (numeric, character, or logical) arranged into a fixed number of rows and columns. Matrix1 &lt;- matrix(1:8, 2, 4) # this creates a matrix of the numbers 1 to 8, in 2 rows and 4 columns. It fills down from column 1 and then column 2, such that the number 3 is the in position [1,2] 2.6.5 Lists Lists hold different types of data i.e. character, numeric and integers and data frames in a single list. You can access the elements of this list with square brackets [] or the dollar sign $ list_example &lt;- list(1, 2L, &quot;3&quot;) # here 1 is stored as a number, 2 an integer and 3 a character. "],["Functions.html", "Chapter 3 Syntax and Functions 3.1 Syntax 3.2 BaseR Functions", " Chapter 3 Syntax and Functions 3.1 Syntax R is its own programming language, and some of the key syntax is not necessarily intuitive. We have covered some already, but here follows some important things to know: Use &lt;- to assign variables e.g. x &lt;- 1 Use c() to combine (i.e. to create) a vector. This is a function in BaseR e.g. c(1,2) Use == to evaluate something as being exactly equal to 1 = 1 #this will return an error 1 == 1 #this will return: [1] TRUE Use %in% to specify that a character string or other data element is contained in some data structure. 1 %in% c(2, 2, 1) # this will return [1] TRUE as 1 is in the vector we&#39;ve defined Use != to specify “is NOT equal to” 1 != 2 #this will return [1] TRUE as 1 is NOT equal to 2 Use :: to specify that a function comes from a specific package. This is necessary if you have two packages which include functions with the same name. library(stringr) stringr::str_split(&quot;Let&#39;s split this string into 10 elements separated by spaces&quot;, &quot; &quot;) #this uses the str_split function from stringr [1] &quot;Let&#39;s&quot; &quot;split&quot; &quot;this&quot; &quot;string&quot; &quot;into&quot; &quot;10&quot; &quot;elements&quot; &quot;separated&quot; &quot;by&quot; &quot;spaces&quot; Use %&gt;% from the Dplyr package - the pipe - to apply multiple functions to an object in turn. As words it would read “… and then” library(dplyr) y &lt;- 25 #define y as the number 25 x &lt;- y %&gt;% #define a new element, x, as 25. Insert the pipe to continue the code chunk on our object, x. sqrt() %&gt;% # square root our element, x. *we do not need to specify that we&#39;re square rooting x as it&#39;s within a pipe print() #print the object we&#39;ve created then manipulated [1] 5 Use ~ (tilde) to define the relationship between two sides of an equation. It separates the left and right side two_by_two &lt;- c(1:4) #this creates a vector of the numbers 1 to 4: 1,2,3,4 print(two_by_two) [1] 1 2 3 4 Even_numbers &lt;- case_when(two_by_two%%2 == 0 ~ &quot;divisible by 2&quot;, # when the element in our two by two vector is divisible by 2, assign the text &quot;divisible by 2&quot; TRUE ~ &quot;not divisible by 2&quot;) #when our first condition is not met, assign &quot;not divisible by 2 print(Even_numbers) [1] &quot;not divisible by 2&quot; &quot;divisible by 2&quot; &quot;not divisible by 2&quot; &quot;divisible by 2&quot; #this will create a vector of 4 character strings, which correspond to the two_by_two vector. Those in position 2 and 4 (the numbers 2 and 4) are divisible by 2, so returns &quot;divisible by 2&quot;. Use parentheses () to pass argumnts to a function Use $ to subset an object, similar to square brackets. Use square brackets [] to grab a subset of data. It appends an index vector to a specified vector. Square brackets can usually be applied in place of $, and are more maleable to the specific task, thoughn they might be slightly less intuitive. See the example below. For more detailed explanation of extracting/subsetting variables see the data manipulation chapter data(&quot;iris&quot;) # load the iris data unique(iris$Species) #show the unique entries in the Species column within the iris data frame [1] setosa versicolor virginica rep(unique(iris$Species), times = 2) # repeat x2 the unique entries from the Species column within the iris data frame [1] setosa versicolor virginica setosa versicolor virginica rep(unique(iris[[5]]), times = 2) #repeat x2 the unique entries from the 5th column within the iris data frame: the species column [1] setosa versicolor virginica setosa versicolor virginica Use {} to evaluate a series of items within the environment of the brackets. More on this when we discuss functions. (Advanced) use {{}}, := and !! when defining functions and needing to specify the nature of objects within them. More on this in chapter 7 - UDFs. 3.2 BaseR Functions Functions are key to coding efficiently and effectively. BaseR contains many functions. Packages also contain specific functions that improve on the inbuilt functionality of R. These functions speed up and optimise your code. To see the function inputs, run ?function(). The help window will appear in the bottom right panel. You can also tab across from the open bracket once writing the function to see the arguments. 3.2.1 Base R and Inbuilt Functions ?() get help on functions specified after the question mark. e.g. run ?rm() rm() removes a specified object from the global environment. This can also be applied to the whole environment with the brush icon. nrow() how many rows are in a data frame nchar() how many characters are in a string gsub(pattern, replace, x) replaces matches in x with a string. Also see stringr and stringi packages for string manipulation. paste() concatenate vectors paste0() concatenate strings is.na() is missing !is.na() is not missing is.null() is null 3.2.2 Programming functions If statements The most important thing to remember with if else statements is to make sure the else is on the same line as the close curly bracket of the if statement. Otherwise the else won’t be tied to the preceding condition. if (condition){ #Do something } else { #Do something different } i &lt;- 3 if (i &gt; 3){ print(&quot;yes&quot;) } else { #because the function is continuous, the else needs to be on the same line as the final curly bracket of the if function. print(&quot;no&quot;) } [1] &quot;no&quot; Adding conditions to if statements using else if i &lt;- 2 if (i &gt; 3){ print(&quot;greater than 3&quot;) } else if ( i == 3) { print(&quot;equal to 3&quot;) } else { print(&quot;less than 3&quot;) } [1] &quot;less than 3&quot; Loops are one of the best ways to optimise your code, but take a bit of time to effectively apply to your work. Examples of applications of loops in our work will be included in the subsequent useful code sections. For loops are usually easier to apply because you tend to know the set of possible values of i. For loop #Generic for(variable in something) { do something } #Example application for (i in 1:4){ j &lt;- i + 10 print(j) } [1] 11 [1] 12 [1] 13 [1] 14 While loop #Generic while(condition){ #do something } #Example application i &lt;- 1 while (i &lt; 6) { print(i) i = i+1 } [1] 1 [1] 2 [1] 3 [1] 4 [1] 5 "],["reading-in-data.html", "Chapter 4 Reading in Data 4.1 Good practice 4.2 Reading in .csvs and excel workbooks 4.3 Connecting to SQL Databases", " Chapter 4 Reading in Data We use R to Manipulate and analyse data. However, R doesn’t have a store of data (aside from some basic pre-loaded datasets), we need to save this outside the R environment and then load or read it into R. Our data tends to be stored in excel files - either workbooks or .csvs - or SQL databases. You can also read in data from Stata and other programmes. Use Google to find packages which allow you to read in this data if this is how your data is stored. In this section we will focus on 3x HE-focused examples of reading in data. The data files are saved in the HEEAT technical resources folder. If you set your working directory as per the code below, you will be able to read in the data files being used. 4.1 Good practice As shown below, documentation is essential. For example, if you download data from HESA and delete the 14-18 rows of table identifiers, a future analyst or QA analyst will struggle to identify the source of the data, or to verify that filters are correct. Equally, with any other data source, if you do not include very clear links to the source, [if relevant] when it was accessed, [if relevant] where from within that source the data come, then it is impossible to verify the source data. 4.2 Reading in .csvs and excel workbooks Depending on your working directory, you can read in any files within that working directory. A reminder of how to check your directory is below. Refer to section 2.2: R Projects for more detail. Briefly, you can either read in a file using the whole file path, or you can do so using the relative path from where you’ve set the working directory. getwd() # if your directory is not where it needs to be to load data or source a file, # set it # Alternatively, you can navigate through to the relative path, as long as the # location is on the same drive. setwd(&quot;&quot;) # All of the data files used in the book are saved in this file path. If you # run this code, all the file reading functions below will load the appropriate # data. setwd(&quot;//vmt1pr-dhfs01/Working/HE-EAT-WKG-FS/HEEAT Technical Resources/R/Core learning RBookdown&quot;) 4.2.1 .csvs The read.csv() function is pre-loaded into R through the utils package. We will usually want to assign the loaded data to an object, so that we have it stored in our global environment. CAH1 subjects is downloaded from HESA. It is saved in the project’s data folder. I have done nothing to the file other than save it as a UTF-8 comma delimited .csv file. In general, it is better to leave sheets downloaded from HESA as they are. This way you can use the data in rows 1:16 to identify a. the source of the data, b. any filters applied to it. CAH1_By_Provider &lt;- read.csv(file = &quot;Data/CAH1 Subjects.csv&quot;) BUT reading this in will create a data frame with lots of blank values, missing column titles and irrelevant rows. Because the top 16 rows are useful for documentation and finding the data source, we want to keep these in the .csv file, but we don’t want R to read them into R, so we tell the read.csv function to skip them. CAH1_By_Provider &lt;- read.csv(file = &quot;Data/CAH1 Subjects.csv&quot;, skip = 16) If we want the column names exactly how they appear in the data, we can add the check.names = FALSE argument. When referencing these columns, you will need to put the name inside tilted apostrophes in order to tell R that the object has spaces in it, otherwise R will read a single column heading as many, and you will get an error. This is why it is common to use underscores when naming objects and variables CAH1_By_Provider &lt;- read.csv(file = &quot;Data/CAH1 Subjects.csv&quot;, skip = 16, check.names = FALSE) Now we have a rectangular dataset with non blank values and the column names we want. But when we check the data format, we find that, other than the UKPRN column, the other numeric data has been read in as character data. We can see this with str(CAH1_By_Provider) You can change this by selecting which columns you want to be numeric. We want columns 3 to 27 to be numeric (i.e. every column from the 3rd column to the 27th) If you simply specify that you want them as.numeric, R will turn the values with commas into NAs. One way to avoid this is using readr’s parse_number argument Numeric_CAH1_By_Provider &lt;- CAH1_By_Provider %&gt;% mutate_at(3:27, readr::parse_number) str(Numeric_CAH1_By_Provider) # we can now see that columns 3 to 27 are numeric You can now explore the data as shown in segment 2.5.1 - Data Frames In some cases, R might create funky column headings. use fileEncoding = \"UTF-8-BOM\" as an argument within the read.csv function if this is the case. Some other examples of making data numeric or replacing NAs with 0 mutate(across(-c(`CAH2 Subject`), ~as.numeric(.x))) mutate(across(-c(Subject), ~readr::parse_number(.x))) mutate(across(everything(), ~replace_na(., 0))) 4.2.2 Large .csvs The fread() function is faster than read.csv, but has less flexibility. 4.2.3 Excel workbooks It might be that you want to store lots of sheets in a single workbook, and want to read in a particular sheet. It also might be that you want to do some manipulation in excel first, then want to read in outputs that have had calculations applied. If you do this, I would advise locking the sheet so that no more changes can be made. Add a “READ ME.txt” file to the folder containing the password to unlock the sheets, or stick it in a sheet at the start of the workbook. Changes will affect the data when re-read into R, post-changes. .csv files are saved as comparabily small files, with no formulas or calculations, just cell values. If you need to save these cell formulas then an excel workbook will probably be preferable. The read_excel function comes from the readxl package library(readxl) Subjects_Allied_To_Medicine &lt;- read_excel(path = &quot;Data/Multiple HESA sheets workbook.xlsx&quot;, sheet = &quot;Subjects Allied To Medicine&quot;, range = &quot;A17:AA237&quot;) 4.3 Connecting to SQL Databases Tom to populate this at a later date. To understand the basics of this, see Analytics Academy session: Connect RStudio to the PDR. Much HE data are also stored on SQL servers. "],["creating-outputs.html", "Chapter 5 Creating outputs 5.1 Writing .csvs 5.2 Saving graphs 5.3 Markdowns, reports, books and presentations", " Chapter 5 Creating outputs R is great for manipulating data and generating graphs, tables or reports. BUT it is usually not where these outputs are best viewed or used by the people for whom they are created. R allows you to export the objects you have generated into accessible formats, the most general ones being: Tables to .csv files Images/Graphs to .JPEG or .PDF files Reports (RMarkdowns) to .html, .PDF or word documents Reports to presentations (see packages to do this in markdown) Reports to books (RBookdowns) This Chapter will focus on the basics: saving graphs and tables.The online resource are plentiful if you know what you’re looking for. There are also chapters in DfE’s analytical academy. Outputs such as shiny apps are beyond the scope of this resource, due to their complexity. 5.1 Writing .csvs This is the most common way to export tables that we have created or manipulated. Excel is more user-friendly than R for viewing data tables. Additionally, if you need to put a table into a MS word report, you might want to export it as a .csv as these are easier to copy or format (such as with colour, bolding or cell merging) prior to inserting the table into your word document. Once again, writing a .csv is dependent on your working directory. You need to set this somewhere proximate to the folder you intend to write the .csv into data(&quot;iris&quot;) # we can write the iris data as a .csv in our outputs folder write.csv(x = iris, file = &quot;Outputs/iris_data.csv&quot;, row.names = FALSE) This creates a .csv file in the Outputs folder called “iris_data”. By specifying that row.names = FALSE, the .csv will not have numbers 1:150 in the first column of the output file. 5.1.1 writing multiple outputs as sheets of an excel file This video shows you how to do this library(xlsx) library(openxlsx) # step 1: load relevant packages step 2: complete analysis as usual, giving # each output a name (i.e. using R_Output_1_Name &lt;- ) step 3: use the following # code to pull together Excel_File_Name &lt;- list(Sheet_Name_1 = R_Output_1_Name, Sheet_Name_2 = R_Output_2_Name) write.xlsx(Excel_File_Name, &quot;./Excel_File_Name.xlsx&quot;, overwrite = TRUE) The packages y 5.2 Saving graphs After creating a graph, the best way to store the output is in a markdown or other feature of R that will update the rendered image if any of the inputs or code change. For ad hoc work, though, we might simply want to export an image. To do this we can either: Create the plot, then click export (in the bottom right “viewer” panel) and save as either a PDF or JPEG Iris_Scatter &lt;- plot(x = iris$Petal.Length, y = iris$Petal.Width) Create a JPG/PDF with a line of code, then plant the plot into it # create the pdf pdf(&quot;Outputs/iris_scatter.pdf&quot;, width = 8, height = 7, paper = &quot;A4&quot;) # create the plot in the pdf Iris_Scatter &lt;- plot(x = iris$Petal.Length, y = iris$Petal.Width) # close the pdf dev.off() # The JPEG arguments are very similar to those for a pdf jpeg(filename = # &#39;Outputs/iris_scatter.jpg&#39;, width = 500, height = 500) You can also open plots and screenshot these if necessary. 5.3 Markdowns, reports, books and presentations To populate at a later date if there is demand. "],["data-manipulation.html", "Chapter 6 Data manipulation 6.1 Selecting 6.2 Filtering 6.3 Summarising 6.4 Grouping by 6.5 Totals 6.6 Mutate 6.7 Pivotting 6.8 Joining data 6.9 Extracting variables 6.10 Others", " Chapter 6 Data manipulation This chapter will focus on the fundamentals of data manipulation. You can identify what the key functions do from the dplyr cheat cheat: As the sheet states, the best way to manipulate data is if your data is tidy - i.e. each variable is in its own column, and each observation is in its own row. Occasionally you will need long data, such as to build graphs. First we’ll read in some Tariff data. We will use this later for grouping by tariff. OFS_Tariffs &lt;- read.csv(\"Data/ofs_provider_tariffs_nospace.csv\") Next we will read in our CAH1 data, which will be the basis of all the manipulation. #Load required packages library(dplyr) library(readr) #Read in OFS data OFS_Tariffs &lt;- read.csv(&quot;Data/ofs_provider_tariffs_nospace.csv&quot;) #Read in CAH1 data CAH1_Data &lt;- read.csv(&quot;Data/CAH1 Subjects.csv&quot;, skip = 16, check.names = F) %&gt;% mutate_at(3:27, readr::parse_number) %&gt;% #we had character data in columns 3 : 27, so turn these into numeric data left_join(OFS_Tariffs %&gt;% select(UKPRN, `Tariff group`), by = &quot;UKPRN&quot;) %&gt;% #we join the tariff data onto our CAH1 data by matching UKPRN. # you can nest manipulation within other functions to ensure only the relevant columns are joined filter(`HE provider` != &quot;Total&quot;) #we remove the &quot;Total&quot; row from the CAH1 data The data has 28 columns: (1) UKPRN, (2) Provider name, (3 - 26) CAH1 subjects’ FPE, (27) Total FPE (at provider), and (28) Tariff group 6.1 Selecting Use the select() function from dplyr to subset columns using their names and type. In addition to selecting and deselecting, you can change the order of columns and rename them with the function. # Specifying columns Providers_Only &lt;- CAH1_Data %&gt;% select(UKPRN, `HE provider`) # Using a predefined vector for the column names Desired_Columns &lt;- c(&quot;UKPRN&quot;, &quot;HE provider&quot;) #Define the vector # Call the vector in the select function Providers_Only2 &lt;- CAH1_Data %&gt;% select(all_of(Desired_Columns)) We can select every column except the UKPRN column No_UKPRN &lt;- CAH1_Data %&gt;% select(-UKPRN) We can select columns based on their index. To only select the first 10 columns. First_10 &lt;- CAH1_Data %&gt;% select(1:10) Be careful using indexes, as if you change prior code, the columns might not remain in the same index position. You can also rename a column within the select function select(new_col_name = old_col_name) or change the order of columns by which order they appear in your select list. Run ?select() or see the function documentation for more features. 6.2 Filtering Use filter() from dplyr to subset a data frame, retaining rows that satisfy conditions. The basic syntax: == is exactly equal to; != is not equal to; %in% (in an array) we can negate %in% to establish a %notin% operator. # Define the function %notin% `%notin%` &lt;- Negate(`%in%`) Other key filters are is.na(x) and !is.na(x). See this site for more operators Basic filters a &lt;- CAH1_Data %&gt;% filter(UKPRN == 10000291) #this gives us the row for Angela Ruskin University, whose UKPRN is 10000291 b &lt;- CAH1_Data %&gt;% filter(`HE provider` == &quot;Anglia Ruskin University&quot;) # as above c &lt;- CAH1_Data %&gt;% filter(`HE provider` %in% c(&quot;Anglia Ruskin University&quot;, &quot;Arden University&quot;, &quot;Birkbeck College&quot;)) #as with the selecting, we could create this vector then call it into a filter function if we wanted to have a store of the vector d &lt;- CAH1_Data %&gt;% filter(grepl(&quot;University&quot;, `HE provider`)) #filter providers that contain the string: &#39;University&#39; e &lt;- CAH1_Data %&gt;% filter(!grepl(&quot;University&quot;, `HE provider`)) #filter the providers than DON&#39;T contain the string: &#39;University&#39; f &lt;- CAH1_Data %&gt;% filter(`HE provider` == &quot;Anglia Ruskin University&quot; | `HE provider` == &quot;Arden University&quot;) # filter either or g &lt;- CAH1_Data %&gt;% filter(grepl(&quot;University&quot;, `HE provider`) &amp; grepl(&quot;College&quot;, `HE provider`)) # filter providers with both university and college in their name h &lt;- CAH1_Data %&gt;% filter(!is.na(Tariff_group)) # filter for the universities for which we have data on their Tariff group. # multiple filters can be applied within the same function j &lt;- CAH1_Data %&gt;% select(`HE provider`, `01 Medicine and dentistry`, `15 Social sciences`) %&gt;% filter(`01 Medicine and dentistry` == 0, `15 Social sciences` &gt; 0) #you can include multiple filters within the same function, as you can do with other data manipulation functions, such as mutate. This is easier to read. advanced filters The across() function allows you to apply a function or functions to multiple columns. See ?across() for the function documentation and examples of combining it with mutate() or filter(). # filter only rows in specified columns that equal == &quot;Total&quot; filter(across(c(he_type_broad, provider_category), ~ str_detect(., pattern = &quot;Total&quot;))) # no letters filter(across(c(INDICATOR, DENOMINATOR), ~ !str_detect(., pattern = &quot;[A-Z]&quot;))) # filter variables are above 5 filter_at(vars(sleep_total, sleep_rem), all_vars(.&gt;5)) # filter non NAs filter_at(vars(everything()), all_vars(!is.na(.)) # filter for rows that have &quot;*&quot; or &quot;A&quot; or &quot;B&quot; or &quot;C&quot; in either the GABIOLOGY or GACHEMISTRY column #&quot;\\\\*&quot; is the way to escape &quot;*&quot; given it&#39;s a special character Filter_List &lt;- c(&quot;\\\\*&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;) #Create a 2 column data frame of students who obtained A*, A, B at A level STEM_Flags &lt;- STEM_Table %&gt;% filter_at(vars(GABIOLOGY, GACHEMISTRY), any_vars(str_detect(. , paste0(&quot;^(&quot;, paste(Filter_List, collapse = &quot;|&quot;), &quot;)&quot;)))) 6.3 Summarising summarise from dplyr creates a new data frame with a row per unique entry in the grouping variable. If no variables are grouped by, it will yield a single row of the function applied to the entire data frame. The code below sums how. # Basic total FPE in 01 column Total_Medicine_Enrollments &lt;- CAH1_Data %&gt;% summarise(Total_FPE = sum(`01 Medicine and dentistry`)) # output table (a data frame with 1 row and 1 column: the number of medicine # and dentistry enrolments) Total_FPE 1 40170 6.4 Grouping by Grouping by a variable does what the name suggests, R will implicitly group by the unique variables in the column(s) specified. It converts a table into a grouped table where operations are performed by group. Running: unique(CAH1_Data$Tariff_group) returns the variables that would be grouped by if we choose to group by tariff group. If we group by Tariff group, we’ll end up with 6 rows as that is how many unique entries were in the Tariff group column. Tariff_Medicine_Enrollments &lt;- CAH1_Data %&gt;% group_by(Tariff_group) %&gt;% summarise(Total_FPE = sum(`01 Medicine and dentistry`)) You can group_by multiple columns at once. This data doesn’t really suit that, but we can create a data frame that does g2 &lt;- CAH1_Data %&gt;% # create a new column of &#39;uni&#39; if the provider name has &#39;University&#39; in it. # &#39;Not uni&#39; if else. mutate(College_Or_Uni = if_else(grepl(&quot;University&quot;, `HE provider`), &quot;Uni&quot;, &quot;Not uni&quot;)) %&gt;% # Group by both Tariff group and COllege or Uni group_by(Tariff_group, College_Or_Uni) %&gt;% # Summarise the FPE doing Medicine and dentistry summarise(Total_FPE = sum(`01 Medicine and dentistry`), .groups = &quot;drop&quot;) # The output, shown below, is a table with a row per Tariff group and per # unique entry in the Colleage_Or_Uni column # A tibble: 11 x 3 Tariff_group College_Or_Uni Total_FPE &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 # HEIs with high average tariff scores Not uni 4870 2 HEIs with high average # tariff scores Uni 29605 3 HEIs with low average tariff scores Uni 1295 4 HEIs # with medium average tariff scores Not uni 0 5 HEIs with medium average tariff # scores Uni 2625 6 Other providers Not uni 0 7 Other providers Uni 0 8 # Specialist HEIs Not uni 0 9 Specialist HEIs Uni 1320 10 NA Not uni 5 11 NA # Uni 450 To ungroup the data, add the argument .groups = \"drop\" to the summarise() function. You sometimes get a warning message if you don’t do this. ungroup() also works. 6.5 Totals Totals can be calculated for subsets of data by using the group_by() function, or by using square brackets[] to sum specific data points. For columns and rows, one way to create totals is the adorn_totals function: adorn_totals(\"row\"). For a column, use: adorn_totals(\"col\"). It is always worth checking whether your data has a total column or row in it, prior to manipulating the data. Tariff_Medicine_Enrollments &lt;- Tariff_Medicine_Enrollments %&gt;% adorn_totals(&quot;row&quot;) # this checks that the totals match up between the data frames we&#39;ve created in # the previous segment. Tariff_Medicine_Enrollments$Total_FPE[7] == Total_Medicine_Enrollments[, 1] # create a total variable object TME_Tail &lt;- Tariff_Medicine_Enrollments %&gt;% slice_tail() %&gt;% pull(Total_FPE) 6.6 Mutate mutate() adds new variables and transforms/overwrites existing ones. As a default mutate will add a column to the right hand side of an existing data frame. You can adjust the position of the added column using the .before = and .after = arguments. If you name the column identically to an existing column, mutate will overwrite/replace the existing column with the newly defined one. # overwriting an existing column #This changes the UKPRN column from containing UKPRN numbers to the text &quot;example text&quot; mutate1 &lt;- CAH1_Data %&gt;% mutate(UKPRN = &quot;example text&quot;) #Creating a new column as the sum of 3 subjects called &quot;Medics_Dentists&quot; mutate2 &lt;- CAH1_Data %&gt;% mutate(Medics_Dentists = `01 Medicine and dentistry` + `02 Subjects allied to medicine` + `05 Veterinary sciences`) %&gt;% select(1:4, 7, 29) #this just selects the columns we are interested in # mutating with multiple conditions. (If you only have 2 conditions, if_else() will be faster.) #This code adds a 1 column called &quot;Colege_Or_Uni&quot; and fills it with &quot;University&quot; if the HE provider name has &quot;University&quot; in it, &quot;College&quot; if the provider name has &quot;College&quot; in it, and &quot;Other&quot; for the rest. mutate3 &lt;- CAH1_Data %&gt;% select(`HE provider`) %&gt;% mutate(College_Or_Uni = case_when(grepl(&quot;University&quot;, `HE provider`) ~ &quot;University&quot;, #notice, any variables with both university and college will be assigned the label &quot;University&quot; grepl(&quot;College&quot;, `HE provider`) ~ &quot;College&quot;, TRUE ~ &quot;Other&quot;)) #this side of the formual tells R what to do in all other cases If we wanted to see how many of each of these entries we had in each HE provider category, we could group_by(College_Or_Uni) %&gt;% count(number = n()). case_when is very powerful and useful. You can use it to overwrite or create a new column based on as many conditions as you desire. The function structure is shown below. You can include multiple cases_when() in the same line of code using &amp;s, BUT be careful not to contradict your existing conditions. Double check your work if creating very complex case_when()s, such as those dependent on multiple different columns mutate(New_Or_Existing_Column_Name = case_when(Other_Column == &quot;Some text&quot; ~ &quot;Fill Column with this&quot;, Other_Column == &quot;Different text&quot; ~ &quot;Fill with this&quot;, TRUE ~ Other_Column)) # you can assign the &#39;all other cases&#39; outcome to be what is contained in an existing column. Mutating specified columns: mutate_at() or mutate(across()). This allows you to run a transformation over multiple columns. You can index the columns: mutate_at(1:4, function), though beware if your column indexes change then the functions won’t work. You can get around this with the vars() in conjunction with mutate_at() or across(c()) in conjunction with mutate(). Making_Character1 &lt;- CAH1_Data %&gt;% mutate(across(c(`01 Medicine and dentistry`, `03 Biological and sport sciences`), as.character)) # Define a function for example below Add_thousand &lt;- function(x) (x + 1000) # mutate 2 specified columns with defined function above mutate4 &lt;- CAH1_Data %&gt;% mutate_at(vars(`01 Medicine and dentistry`, `03 Biological and sport sciences`), Add_thousand) 6.7 Pivotting The format of data matters. Clean data can be in two formats: “wide” and “long”. In wide data, data points corresponding to a variable are spread across multiple columns. This variable might be an individual, university or other entity. In long data, there are multiple records (rows) for each entity. Observe the basic data frame below: # This code creates a fictional WIDE data frame. There is one row for horses # and 1 row for cats. Horses_vs_Cats &lt;- tibble(animal = c(&quot;horse&quot;, &quot;cat&quot;), weight = c(&quot;500kg&quot;, &quot;6kg&quot;), height = c(&quot;2.5m&quot;, &quot;0.4m&quot;), home = c(&quot;field&quot;, &quot;house&quot;)) # The Data # A tibble: 2 x 4 | animal | weight | height | home # ____________________________________ 1 | horse | 500kg | 2.5m | field 2 | cat # | 6kg | 0.4m | house # In LONG format, that tibble looks like this: A tibble: 6 x 3 | animal | # category | answer _________________________________ 1 | horse | weight | # 500kg 2 | horse | height | 2.5m 3 | horse | home | field 4 | cat | weight | # 6kg 5 | cat | height | 0.4m 6 | cat | home | house # For completeness, the code to perform this transformation is: # pivot_longer(-animal, names_to = &#39;category&#39;, values_to = &#39;answer&#39;) Wide to long Long_CAH1 &lt;- CAH1_Data %&gt;% select(-Tariff_group) %&gt;% pivot_longer(-c(`UKPRN`, `HE provider`), #This vector contains the columns to hold on the left hand side of the data frame and essential &#39;not pivot&#39; names_to = &quot;Subject&quot;, #The name of the column title that will contain the former column headings values_to = &quot;FPE&quot;) #Name of the data column Long to wide (restoring our original data frame) Wide_CAH1 &lt;- Long_CAH1 %&gt;% pivot_wider(names_from = Subject, values_from = FPE) The values_fill = ... argument is useful when converting long data to wide data if not all rows have a data point for each column. 6.8 Joining data There are four primary joining functions in the dplyr package. Each does a slightly different thing, adding y to x, matching rows based on the keys. Searching the help bar, for any of left_join(), right_join(), full_join() and inner_join() should show that it is relatively straightforward. Some less immediately clear things are: Matching two columns that do not have the same name. This is done within the by = ... argument, such as: left_join(data_frame1, data_frame2, by = c(\"column_name_in_D1\" = \"column_name_in_D2\")). If you are working in a dplyr pipe (i.e. you are using %&gt;%), the x data frame is implicitly included in the function. In this way you could write `data_frame1 %&gt;% left_join(data_frame2, by = “matching_column”). Matching multiple columns. If rows do not have a unique identifier - instead, their uniqueness comes from a combination of variables, perhaps the lifetime earnings of a certain subject at a particular university, which could not be matched from either the university or subject alone - then you will need to match multiple columns at once. This can also be done from within the by = ... argument, using a vector of columns to match. This could be in conjunction with the non-identical names method, shown above, but in it’s simplest form, the code would look like: left_join(data_frame1, data_frame2, by = c(\"column1\", \"column2\", \"column3\")), where the three columns are all in both data_frame1 and data_frame2. 6.9 Extracting variables Often you need to pull out specific data points. There are multiple ways to do this; some are more robust than others, but use whatever will work for you. If you know exactly which index position the data point is in and will always be in, you can subset with the data point position. That is, how many rows down it is and how many columns across it is. The issue is, if you change or update your analysis, and the data point moves, this code will extract the incorrect data point, as your data have shifted. This is also more favourable for whoever comes to QA your work. library(dplyr) library(tidyverse) data(&quot;iris&quot;) # you can extract the data point in the 150th row and 2nd column x &lt;- iris[150, 2] Instead of row and column number, you can subset using row and column names. In the iris data the row names are the text “1”:“150”. The column names (which can be seen with the names() function) are text strings. # you can extract the data point in the row whose name is &quot;150&quot; and whose column name is &quot;Sepal.Width y &lt;- iris[&quot;150&quot;, &quot;Sepal.Width&quot;] # you can generalise the code, given we know the data frame has 150 rows. print(nrow(iris)) # check the number of rows [1] 150 # extract the data point whose row name is 150 and whose column name is Sepal.Width # without the as.character() function, we would extract the element in the 150th row. # In this dataset, due to the names being the same as numbers you get the same outcome z &lt;- iris[as.character(nrow(iris)), &quot;Sepal.Width&quot;] In order to make a data frame that’s easy to subset, you might want to define the row names. When defining row names, each one needs to be unique. I.e. you should use wide data, and the row names should be a unique column. For this example, we’ll create our own data frame. However, if you want to see a dataset where a column has already been made into row names, see the mtcars data. A pre-loaded dataset in R. (rundata(\"mtcars)) # Define a 5x3 data frame Test_Data &lt;- as.data.frame(tibble(name = c(&quot;Sean&quot;, &quot;Tom&quot;, &quot;Yasmin&quot;, &quot;Henna&quot;, &quot;Matt&quot;), office = c(&quot;SB&quot;, &quot;SB&quot;, &quot;Bris&quot;, &quot;SB&quot;, &quot;SB&quot;), manager = c(&quot;James&quot;, &quot;Gabe&quot;, &quot;Henna&quot;, &quot;Tim&quot;, &quot;Tim&quot;))) #It looks like this: # name office manager # &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; # 1 Sean SB James # 2 Tom SB Gabe # 3 Yasmin Bris Henna # 4 Henna SB Tim # 5 Matt SB Tim # You&#39;ll see our row names are 1:5, therefore you can extract the first row in the manager column like this: Seans_Manager1 &lt;- Test_Data[&quot;1&quot;, &quot;manager&quot;] print(Seans_Manager1) [1] &quot;James&quot; # NOTE: if the Test_Data was not a data frame (i.e. was just a tibble). You would need to do pull(Test_Data[&quot;1&quot;, &quot;manager&quot;]) OR Test_Data[&quot;1&quot;, &quot;manager&quot;] %&gt;% pull() # We can give the table row names using the column to row names # This wouldn&#39;t work for the `office` column because there are multiple SBs Col_Indexed_Test_Data &lt;- Test_Data %&gt;% column_to_rownames(., var = &quot;name&quot;) # Our data now look like this # office manager # Sean SB James # Tom SB Gabe # Yasmin Bris Henna # Henna SB Tim # Matt SB Tim #Now we can pull with specified inputs. Seans_Manager2 &lt;- Col_Indexed_Test_Data[&quot;Sean&quot;, &quot;manager&quot;] print(Seans_Manager2) [1] &quot;James&quot; An alternative way to extract data is by filtering columns until you end up with a single row, at which point you can use the pull() function to extract the data point in the column you are after. Seans_Manager3 &lt;- Test_Data %&gt;% filter(name == &quot;Sean&quot;) %&gt;% pull(manager) Use [[]] to return an element in a list; use for recurssive indexing. See iris[[2]] vs iris[2]. Double square brackets are often necessary to pinpoint elements. 6.10 Others Most data manipulation functions can be found in the dplyr cheat sheet and are fairly intuitive to use. Particularly useful are binding functions: cbind() in BaseR, bind_cols() in dplyr. Also pull() and rename() "],["user-defined-functions.html", "Chapter 7 User-defined Functions 7.1 Overview 7.2 Basic examples 7.3 Returning objects 7.4 Passing objects 7.5 Setting default inputs 7.6 Using Loops", " Chapter 7 User-defined Functions The advanced technicalities of UDFs are, in most instances, outstide the scope of this book. If you would like to read more about the specifics covered here, some good resources are: Quasiquotation Tidy evaluation (data masking and tidy selection) Assignment by reference 7.1 Overview This chapter is a quick introduction to UDFs. It also aims to give you some of the tools to overcome specific issues you are likely to encounter as you start to use them more frequently. UDFs give you the power to automate and generalise code. They allow analysts to retain control over function inputs, whilst also minimising the risk of error. User-defined functions are easier to QA and are more readable than large chunks of repeated code. Making changes to UD functions is also faster than finding the exact places to make a change if this change needs to be iterated across multiple code chunks. In general, a good rule is to write a function if you are going to be using a chunk of code more than twice (you can also write a function retrospectively if you notice you’ve copied a chunk of code several times). As with everything in this book, there is no single way to go about writing functions. Do what works for you, and what helps you to achieve the goal you set out. In order to write a function you need: a name for your function; function input parameters; an operation for the function to perform; and an output or outputs. 7.2 Basic examples In the most basic sense, a function can be used to perform the operation fed to it. In this way you could: firstly, copy and paste any working code into a UD function; save the function; then run the function; and finally observe that the code has been executed. # Using the existing print() function: print(&quot;Hi my name is&quot;) # will print the string &quot;Hi my name is&quot; [1] &quot;Hi my name is&quot; # Creating our own function # This assigns a function to the name Print_Function # The function will be performed on all elements in the curly brackets, denoted by the &quot;.&quot; in the function inputs. In actual fact you could put anything in here; it won&#39;t be evaluated. # The curly brackets open and close the function. The code between is the operation. Print_Function &lt;- function(.){ # Define and name the function print(&quot;Hi my name is&quot;) #give it an operation } #close it Print_Function() # run the function (with no specified input parameters) [1] &quot;Hi my name is&quot; 7.3 Returning objects Objects created within a function will not be stored in the global environment, unless R is told specifically to do this. This is very useful if you want to create lots of objects temporarily. It does, however, mean you need to know how to extract the relevant objects from your data frame. The usual &lt;- (assignment) operator will create an object to be used within the function, but this will not be exported to the global environment. The &lt;&lt;- operator will assign the object created to the global environment regardless of where it appears in the function, or whether your function is run to designate a new object. See below for more clarity. Assigmment function 1 creates 3 variables: a, b and d. I use “d” because c is the combine function itself. We then run the function, which creates the variables but doesn’t assign them to any objects in the global environment. Assignment_Func_1 &lt;- function(.) { a &lt;- 1 b &lt;- 2 d &lt;- 3 } Assignment_Func_1() Assingment function 2 is identical to #1, except that we designate the function to the variable x. This assigns x the value 3 because d was the final object created in the function. Assignment_Func_2 &lt;- function(.){ a &lt;- 1 b &lt;- 2 d &lt;- 3 } x &lt;- Assignment_Func_2() print(x) [1] 3 To demonstrate that the objects a and b are created within the function, see the iteration 2.1 below. The function still outputs the value of d because it is the last thing created, but we use the prior objects to generate d. Assignment_Func_2b &lt;- function(.){ a &lt;- 1 b &lt;- 2 d &lt;- a + b } x &lt;- Assignment_Func_2b() print(x) [1] 3 If we wanted to specify which object to assign as our output we could use the return() function. Assignment function 3 finishes by returning a, therefore, when we assign the output of the function to our variable, x, it is assigned the value 1 (equivalent to a). Assignment_Func_3 &lt;- function(.){ a &lt;- 1 b &lt;- 2 d &lt;- 3 return(a) } x &lt;- Assignment_Func_3() print(x) [1] 1 We can also assign objects created within the function using the &lt;&lt;- operator. If you were to run print(a), print(b) or print(d) in your console at any point so far you would have seen this error: Error in print(b) : object 'b' not found. We can, however, create these objects. Assignment function 4 does this. It creates 2 objects, b and d, in addition to assigning x the value of 1 (because we have returned (a)) Assignment_Func_4 &lt;- function(.){ a &lt;- 1 b &lt;&lt;- 2 d &lt;&lt;- 3 return(a) } x &lt;- Assignment_Func_4() print(b) [1] 2 print(x) [1] 1 7.4 Passing objects You can pass objects through functions. This helps to generalise ta function’s inputs. Inputs might be objects, vectors, strings, numbers, columns etc. Print_Object &lt;- function(Input_String){ print(Input_String) } Print_Object(Input_String = &quot;Hello, is it me you&#39;re looking for&quot;) [1] &quot;Hello, is it me you&#39;re looking for&quot; When passing more complicated inputs, you might need to know about other operators. The main things to be aware of are {{}}, := and !!. To do this, we will reload the iris data and play about with generalising our inputs. You might also need to be careful about how an input is read in: ether as as string (wrapped in speech marks) or an object. library(dplyr) #Load dplyr package data(&quot;iris&quot;) #Load the iris data 7.4.1 Creating the function # Create an average sepal length table Summary_Function &lt;- function(.) { Summary_Table &lt;- iris %&gt;% group_by(Species) %&gt;% summarise(Average_Sepal_Length = mean(Sepal.Length)) } Av_Sepal_Length_Table &lt;- Summary_Function() print(Av_Sepal_Length_Table) # # A tibble: 3 x 2 Species Average_Sepal_Length 1 setosa 5.01 2 versicolor # 5.94 3 virginica 6.59 7.4.2 Passing data # Create an average sepal length table Summary_Function &lt;- function(DATA_FRAME) { Summary_Table &lt;- DATA_FRAME %&gt;% group_by(Species) %&gt;% summarise(Average_Sepal_Length = mean(Sepal.Length)) } Av_Sepal_Length_Table &lt;- Summary_Function(DATA_FRAME = iris) print(Av_Sepal_Length_Table) # # A tibble: 3 x 2 Species Average_Sepal_Length 1 setosa 5.01 2 versicolor # 5.94 3 virginica 6.59 Now, as we try to involve more complex arguments, we need to tell R more about the objects we are passing through it. Different functions work in different ways. The group_by() and summarise() functions look for the variables as quoted arguments. In order to tell R that the object being passed is in fact a variable name, we need to use {{}} (curly-curly). Also, note that we’ve had to use := (colon equals) instead of =. This will also be true for mutate() functions when you mutate columns by having passed the column name through the function. It allows you to perform assignments by reference. # Create an average sepal length table Summary_Function &lt;- function(DATA_FRAME, GROUP_BY_COL, SUMMARY_COL) { Summary_Table &lt;- DATA_FRAME %&gt;% group_by({ { GROUP_BY_COL } }) %&gt;% summarise(`:=`({ { SUMMARY_COL } }, mean(Sepal.Length))) } Av_Sepal_Length_Table &lt;- Summary_Function(DATA_FRAME = iris, GROUP_BY_COL = Species, SUMMARY_COL = Average_Sepal_Length) print(Av_Sepal_Length_Table) # # A tibble: 3 x 2 Species Average_Sepal_Length 1 setosa 5.01 2 versicolor # 5.94 3 virginica 6.59 Finally, it might be that you need your inputs to change between quoted and unquoted arguments. In the example below, given the nature of the vector, these elements need to be in quotations. But when we call them in our dplyr chain, we want R to recognise them as objects. We use as.name, a base R fuction that takes a string (or a variable containing a string) and returns the content of the string as a variable name. The !! (bang-bang) tells the summarise function to not take the value as it is, but to substitute the real value. # Create an average sepal length table Summary_Function &lt;- function(Col_Vector, i) { # depending on the value of i, this will extract the element in position i # of the Col_Vector. It assigns the string to an element, Col_Averaging Col_Averaging &lt;- Col_Vector[i] Summary_Table &lt;- iris %&gt;% group_by(Species) %&gt;% summarise(`:=`(!!as.name(paste0(&quot;Average_&quot;, Col_Averaging)), mean(!!as.name(Col_Averaging)))) #the paste0 is to generalise the column title as a concatenaetion of Average and the Column we select. } Av_Table &lt;- Summary_Function(Col_Vector = c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, &quot;Petal.Length&quot;, &quot;Petal.Width&quot;), i = 2) print(Av_Table) # A tibble: 3 x 2 Species Average_Sepal.Width 1 setosa 3.43 2 versicolor 2.77 3 # virginica 2.97 7.5 Setting default inputs You can tell a function that if an input is not specified otherwise, to autofill that argument with something pre-determined. My_Print_Function &lt;- function(Input_String = &quot;The assigned default input&quot;){ print(Input_String) } My_Print_Function() [1] &quot;The assigned default input&quot; My_Print_Function(&quot;Print this instead&quot;) [1] &quot;print this instead&quot; Another key for setting defaults is ensuring that your function can work both on its own and within dplyr pipes. You can often get away with setting one of the function arguments to be “data_frame”. If you are in a dplyr pipe, you will not need to manually specify this argument because R will just assign the first element you’re working with to be a data frame. If you want to be able to call the data_frame object and interact with it, then you should tell R this. Setting the argument: data_frame = .data will allow you to do this. In this way, if you are working outside a dplyr pipe, you can reassign the object such that data_frame = insert_name_of_your_data . Alternatively, if you are in a pipe, you will be able to use the data_frame object within the function. 7.6 Using Loops Loops increase the power (and running time) of functions . They allow you to specify the array sets on which to apply functions. The two most used loop functions are for() and while(). Generally, for() loops are easier to use, unless the condition changes as the function evolves. In the most basic sense, these formulae do the same thing: # 1. i &lt;- 1 while (i &lt; 4) { print(i) i &lt;- i + 1 } # 2. for (i in 1:3) { print(i) } While loops are useful when we don’t know exactly when to terminate the loop. They do, however, require us to define an evolving condition. More common is to know the set around which we need to loop. This will usually be a number or vector (remember vectors can vary in length). You can apply vectors over multiple objects using the apply() family of functions: tapply(), sapply(), lapply(). You can also achieve this with loops # deinfe a vector of the data frame names df_vector &lt;- c(“df1”, “df2”, “df3) # loop around the vector you&#39;ve defined for(i in df_vector){ # assign an object, df, to be the object i df &lt;- get(i) %&gt;% # transform object mutate(sdaiusfd) # reassign the object in the global environment with the same name as i to be the df we&#39;ve just manipulated # you could change the name of i with paste0() if you wanted assign(i, df) } # remove elements used in loop rm(i, df) For more examples or applications, feel free to contact me: thomas.harris@education.gov.uk "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
